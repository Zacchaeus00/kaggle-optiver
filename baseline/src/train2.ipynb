{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from imp import reload\n",
    "import warnings\n",
    "from utils import util\n",
    "from sklearn import model_selection\n",
    "reload(util)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('../data/20210809_encode.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_stock = df_all[['stock_id']+df_all.columns[df_all.columns.str.endswith('_stock')].tolist()]\n",
    "df_all_stock.drop_duplicates().to_pickle('../data/20210809.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': 20000,\n",
    "    'objective': 'rmse', # poisson\n",
    "    'boosting_type': 'gbdt', # dart\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.01,\n",
    "    'subsample': 0.8,\n",
    "    'subsample_freq': 4,\n",
    "    'feature_fraction': 0.8,\n",
    "    'lambda_l1': 1,\n",
    "    'lambda_l2': 1,\n",
    "    'seed':46,\n",
    "    'early_stopping_rounds': 500,\n",
    "    'verbose': -1\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>Bnum</th>\n",
       "      <th>waproll_std5_B_mean</th>\n",
       "      <th>waproll_std5_B_std</th>\n",
       "      <th>waproll_std5_B_skew</th>\n",
       "      <th>waproll_std5_B_autocorr</th>\n",
       "      <th>waproll_std10_B_mean</th>\n",
       "      <th>waproll_std10_B_std</th>\n",
       "      <th>waproll_std10_B_skew</th>\n",
       "      <th>waproll_std10_B_autocorr</th>\n",
       "      <th>...</th>\n",
       "      <th>__book_wap2_lambda_____min___stock</th>\n",
       "      <th>__book_wap_mean_lambda_____mean___stock</th>\n",
       "      <th>__book_wap_mean_lambda_____std___stock</th>\n",
       "      <th>__book_wap_mean_lambda_____max___stock</th>\n",
       "      <th>__book_wap_mean_lambda_____min___stock</th>\n",
       "      <th>__book_wap_diff_lambda_____mean___stock</th>\n",
       "      <th>__book_wap_diff_lambda_____std___stock</th>\n",
       "      <th>__book_wap_diff_lambda_____max___stock</th>\n",
       "      <th>__book_wap_diff_lambda_____min___stock</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>159</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.984711</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>1.309386</td>\n",
       "      <td>0.924732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.03336</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.70394</td>\n",
       "      <td>0.004615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>105</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.938263</td>\n",
       "      <td>0.747746</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.179212</td>\n",
       "      <td>0.908148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.03336</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.70394</td>\n",
       "      <td>0.002474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>130</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.716425</td>\n",
       "      <td>0.730194</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.363781</td>\n",
       "      <td>0.917034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.03336</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.70394</td>\n",
       "      <td>0.002831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>101</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1.439628</td>\n",
       "      <td>0.708243</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.553793</td>\n",
       "      <td>0.900866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.03336</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.70394</td>\n",
       "      <td>0.002201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>104</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.922427</td>\n",
       "      <td>0.788645</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.674093</td>\n",
       "      <td>0.898002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.03336</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.70394</td>\n",
       "      <td>0.002090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_id  Bnum  waproll_std5_B_mean  waproll_std5_B_std  \\\n",
       "0        5   159             0.000191            0.000104   \n",
       "1       11   105             0.000150            0.000118   \n",
       "2       16   130             0.000135            0.000061   \n",
       "3       31   101             0.000139            0.000098   \n",
       "4       62   104             0.000116            0.000076   \n",
       "\n",
       "   waproll_std5_B_skew  waproll_std5_B_autocorr  waproll_std10_B_mean  \\\n",
       "0             0.984711                 0.748098              0.000244   \n",
       "1             0.938263                 0.747746              0.000229   \n",
       "2             0.716425                 0.730194              0.000157   \n",
       "3             1.439628                 0.708243              0.000193   \n",
       "4             0.922427                 0.788645              0.000158   \n",
       "\n",
       "   waproll_std10_B_std  waproll_std10_B_skew  waproll_std10_B_autocorr  ...  \\\n",
       "0             0.000111              1.309386                  0.924732  ...   \n",
       "1             0.000116              0.179212                  0.908148  ...   \n",
       "2             0.000049              0.363781                  0.917034  ...   \n",
       "3             0.000101              0.553793                  0.900866  ...   \n",
       "4             0.000074              0.674093                  0.898002  ...   \n",
       "\n",
       "   __book_wap2_lambda_____min___stock  \\\n",
       "0                            0.001142   \n",
       "1                            0.001142   \n",
       "2                            0.001142   \n",
       "3                            0.001142   \n",
       "4                            0.001142   \n",
       "\n",
       "   __book_wap_mean_lambda_____mean___stock  \\\n",
       "0                                 0.004135   \n",
       "1                                 0.004135   \n",
       "2                                 0.004135   \n",
       "3                                 0.004135   \n",
       "4                                 0.004135   \n",
       "\n",
       "   __book_wap_mean_lambda_____std___stock  \\\n",
       "0                                0.003384   \n",
       "1                                0.003384   \n",
       "2                                0.003384   \n",
       "3                                0.003384   \n",
       "4                                0.003384   \n",
       "\n",
       "   __book_wap_mean_lambda_____max___stock  \\\n",
       "0                                 0.03336   \n",
       "1                                 0.03336   \n",
       "2                                 0.03336   \n",
       "3                                 0.03336   \n",
       "4                                 0.03336   \n",
       "\n",
       "   __book_wap_mean_lambda_____min___stock  \\\n",
       "0                                0.000732   \n",
       "1                                0.000732   \n",
       "2                                0.000732   \n",
       "3                                0.000732   \n",
       "4                                0.000732   \n",
       "\n",
       "   __book_wap_diff_lambda_____mean___stock  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "\n",
       "   __book_wap_diff_lambda_____std___stock  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "\n",
       "   __book_wap_diff_lambda_____max___stock  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "\n",
       "   __book_wap_diff_lambda_____min___stock    target  \n",
       "0                                 4.70394  0.004615  \n",
       "1                                 4.70394  0.002474  \n",
       "2                                 4.70394  0.002831  \n",
       "3                                 4.70394  0.002201  \n",
       "4                                 4.70394  0.002090  \n",
       "\n",
       "[5 rows x 218 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_all[df_all.columns.difference(['target'])]\n",
    "y_train = df_all['target']\n",
    "features = df_all[df_all.columns.difference(['time_id','target'])].columns.tolist()\n",
    "pd.DataFrame(features).to_pickle('../data/features_name_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's rmse: 0.000506455\ttraining's RMSPE: 0.234571\tvalid_1's rmse: 0.000513309\tvalid_1's RMSPE: 0.235949\n",
      "[500]\ttraining's rmse: 0.000476751\ttraining's RMSPE: 0.220813\tvalid_1's rmse: 0.000485588\tvalid_1's RMSPE: 0.223207\n",
      "[750]\ttraining's rmse: 0.000465217\ttraining's RMSPE: 0.21547\tvalid_1's rmse: 0.000476477\tvalid_1's RMSPE: 0.219019\n",
      "[1000]\ttraining's rmse: 0.000457122\ttraining's RMSPE: 0.211721\tvalid_1's rmse: 0.00047089\tvalid_1's RMSPE: 0.21645\n",
      "[1250]\ttraining's rmse: 0.000450189\ttraining's RMSPE: 0.20851\tvalid_1's rmse: 0.000466462\tvalid_1's RMSPE: 0.214415\n",
      "[1500]\ttraining's rmse: 0.000444549\ttraining's RMSPE: 0.205898\tvalid_1's rmse: 0.000463038\tvalid_1's RMSPE: 0.212842\n",
      "[1750]\ttraining's rmse: 0.000439011\ttraining's RMSPE: 0.203333\tvalid_1's rmse: 0.000459549\tvalid_1's RMSPE: 0.211238\n",
      "[2000]\ttraining's rmse: 0.000434786\ttraining's RMSPE: 0.201376\tvalid_1's rmse: 0.000457572\tvalid_1's RMSPE: 0.210329\n",
      "[2250]\ttraining's rmse: 0.000430961\ttraining's RMSPE: 0.199604\tvalid_1's rmse: 0.000456175\tvalid_1's RMSPE: 0.209687\n",
      "[2500]\ttraining's rmse: 0.000426852\ttraining's RMSPE: 0.197701\tvalid_1's rmse: 0.00045381\tvalid_1's RMSPE: 0.208599\n",
      "[2750]\ttraining's rmse: 0.000423635\ttraining's RMSPE: 0.196211\tvalid_1's rmse: 0.000452639\tvalid_1's RMSPE: 0.208061\n",
      "[3000]\ttraining's rmse: 0.000420579\ttraining's RMSPE: 0.194796\tvalid_1's rmse: 0.000451242\tvalid_1's RMSPE: 0.207419\n",
      "[3250]\ttraining's rmse: 0.000417771\ttraining's RMSPE: 0.193495\tvalid_1's rmse: 0.000450168\tvalid_1's RMSPE: 0.206925\n",
      "[3500]\ttraining's rmse: 0.000415004\ttraining's RMSPE: 0.192214\tvalid_1's rmse: 0.000448927\tvalid_1's RMSPE: 0.206355\n",
      "[3750]\ttraining's rmse: 0.000412699\ttraining's RMSPE: 0.191146\tvalid_1's rmse: 0.000448729\tvalid_1's RMSPE: 0.206264\n",
      "[4000]\ttraining's rmse: 0.00041038\ttraining's RMSPE: 0.190072\tvalid_1's rmse: 0.000447955\tvalid_1's RMSPE: 0.205908\n",
      "[4250]\ttraining's rmse: 0.000408086\ttraining's RMSPE: 0.18901\tvalid_1's rmse: 0.000447181\tvalid_1's RMSPE: 0.205553\n",
      "[4500]\ttraining's rmse: 0.000405995\ttraining's RMSPE: 0.188041\tvalid_1's rmse: 0.000446762\tvalid_1's RMSPE: 0.20536\n",
      "[4750]\ttraining's rmse: 0.00040405\ttraining's RMSPE: 0.18714\tvalid_1's rmse: 0.000446452\tvalid_1's RMSPE: 0.205217\n",
      "[5000]\ttraining's rmse: 0.000402243\ttraining's RMSPE: 0.186304\tvalid_1's rmse: 0.000446023\tvalid_1's RMSPE: 0.20502\n",
      "[5250]\ttraining's rmse: 0.000400274\ttraining's RMSPE: 0.185391\tvalid_1's rmse: 0.000445477\tvalid_1's RMSPE: 0.204769\n",
      "[5500]\ttraining's rmse: 0.000398449\ttraining's RMSPE: 0.184546\tvalid_1's rmse: 0.000444959\tvalid_1's RMSPE: 0.204531\n",
      "[5750]\ttraining's rmse: 0.00039667\ttraining's RMSPE: 0.183722\tvalid_1's rmse: 0.000444649\tvalid_1's RMSPE: 0.204388\n",
      "[6000]\ttraining's rmse: 0.000394915\ttraining's RMSPE: 0.182909\tvalid_1's rmse: 0.000444304\tvalid_1's RMSPE: 0.20423\n",
      "[6250]\ttraining's rmse: 0.000393278\ttraining's RMSPE: 0.182151\tvalid_1's rmse: 0.000444075\tvalid_1's RMSPE: 0.204125\n",
      "[6500]\ttraining's rmse: 0.000391526\ttraining's RMSPE: 0.18134\tvalid_1's rmse: 0.000443588\tvalid_1's RMSPE: 0.203901\n",
      "[6750]\ttraining's rmse: 0.00038992\ttraining's RMSPE: 0.180596\tvalid_1's rmse: 0.000443176\tvalid_1's RMSPE: 0.203711\n",
      "[7000]\ttraining's rmse: 0.000388357\ttraining's RMSPE: 0.179872\tvalid_1's rmse: 0.000442732\tvalid_1's RMSPE: 0.203507\n",
      "[7250]\ttraining's rmse: 0.000386699\ttraining's RMSPE: 0.179104\tvalid_1's rmse: 0.000442252\tvalid_1's RMSPE: 0.203287\n",
      "[7500]\ttraining's rmse: 0.000385136\ttraining's RMSPE: 0.17838\tvalid_1's rmse: 0.000441917\tvalid_1's RMSPE: 0.203133\n",
      "[7750]\ttraining's rmse: 0.000383756\ttraining's RMSPE: 0.177741\tvalid_1's rmse: 0.00044179\tvalid_1's RMSPE: 0.203075\n",
      "[8000]\ttraining's rmse: 0.000382158\ttraining's RMSPE: 0.177001\tvalid_1's rmse: 0.000441366\tvalid_1's RMSPE: 0.202879\n",
      "[8250]\ttraining's rmse: 0.000380794\ttraining's RMSPE: 0.176369\tvalid_1's rmse: 0.000441143\tvalid_1's RMSPE: 0.202777\n",
      "[8500]\ttraining's rmse: 0.000379378\ttraining's RMSPE: 0.175713\tvalid_1's rmse: 0.00044112\tvalid_1's RMSPE: 0.202766\n",
      "[8750]\ttraining's rmse: 0.000378078\ttraining's RMSPE: 0.175111\tvalid_1's rmse: 0.000440951\tvalid_1's RMSPE: 0.202689\n",
      "[9000]\ttraining's rmse: 0.000376572\ttraining's RMSPE: 0.174414\tvalid_1's rmse: 0.00044055\tvalid_1's RMSPE: 0.202504\n",
      "[9250]\ttraining's rmse: 0.000375153\ttraining's RMSPE: 0.173756\tvalid_1's rmse: 0.000440089\tvalid_1's RMSPE: 0.202293\n",
      "[9500]\ttraining's rmse: 0.000373773\ttraining's RMSPE: 0.173117\tvalid_1's rmse: 0.000439894\tvalid_1's RMSPE: 0.202203\n",
      "[9750]\ttraining's rmse: 0.00037249\ttraining's RMSPE: 0.172523\tvalid_1's rmse: 0.000439577\tvalid_1's RMSPE: 0.202057\n",
      "[10000]\ttraining's rmse: 0.000371258\ttraining's RMSPE: 0.171953\tvalid_1's rmse: 0.000439447\tvalid_1's RMSPE: 0.201998\n",
      "[10250]\ttraining's rmse: 0.000369974\ttraining's RMSPE: 0.171358\tvalid_1's rmse: 0.000439233\tvalid_1's RMSPE: 0.201899\n",
      "[10500]\ttraining's rmse: 0.00036852\ttraining's RMSPE: 0.170684\tvalid_1's rmse: 0.00043886\tvalid_1's RMSPE: 0.201728\n",
      "[10750]\ttraining's rmse: 0.000367221\ttraining's RMSPE: 0.170082\tvalid_1's rmse: 0.00043859\tvalid_1's RMSPE: 0.201603\n",
      "[11000]\ttraining's rmse: 0.000366021\ttraining's RMSPE: 0.169527\tvalid_1's rmse: 0.000438474\tvalid_1's RMSPE: 0.20155\n",
      "[11250]\ttraining's rmse: 0.000364874\ttraining's RMSPE: 0.168996\tvalid_1's rmse: 0.000438379\tvalid_1's RMSPE: 0.201506\n",
      "[11500]\ttraining's rmse: 0.000363705\ttraining's RMSPE: 0.168454\tvalid_1's rmse: 0.000438292\tvalid_1's RMSPE: 0.201467\n",
      "[11750]\ttraining's rmse: 0.000362531\ttraining's RMSPE: 0.16791\tvalid_1's rmse: 0.000438206\tvalid_1's RMSPE: 0.201427\n",
      "[12000]\ttraining's rmse: 0.000361396\ttraining's RMSPE: 0.167385\tvalid_1's rmse: 0.000438099\tvalid_1's RMSPE: 0.201378\n",
      "[12250]\ttraining's rmse: 0.000360301\ttraining's RMSPE: 0.166878\tvalid_1's rmse: 0.00043805\tvalid_1's RMSPE: 0.201355\n",
      "[12500]\ttraining's rmse: 0.000359181\ttraining's RMSPE: 0.166359\tvalid_1's rmse: 0.000438009\tvalid_1's RMSPE: 0.201337\n",
      "[12750]\ttraining's rmse: 0.000358035\ttraining's RMSPE: 0.165828\tvalid_1's rmse: 0.00043791\tvalid_1's RMSPE: 0.201291\n",
      "[13000]\ttraining's rmse: 0.000356835\ttraining's RMSPE: 0.165272\tvalid_1's rmse: 0.000437714\tvalid_1's RMSPE: 0.201201\n",
      "[13250]\ttraining's rmse: 0.000355665\ttraining's RMSPE: 0.16473\tvalid_1's rmse: 0.000437588\tvalid_1's RMSPE: 0.201143\n",
      "[13500]\ttraining's rmse: 0.000354524\ttraining's RMSPE: 0.164202\tvalid_1's rmse: 0.00043746\tvalid_1's RMSPE: 0.201084\n",
      "[13750]\ttraining's rmse: 0.000353462\ttraining's RMSPE: 0.16371\tvalid_1's rmse: 0.000437335\tvalid_1's RMSPE: 0.201027\n",
      "[14000]\ttraining's rmse: 0.000352441\ttraining's RMSPE: 0.163237\tvalid_1's rmse: 0.000437213\tvalid_1's RMSPE: 0.200971\n",
      "[14250]\ttraining's rmse: 0.00035145\ttraining's RMSPE: 0.162778\tvalid_1's rmse: 0.000437196\tvalid_1's RMSPE: 0.200963\n",
      "[14500]\ttraining's rmse: 0.000350371\ttraining's RMSPE: 0.162278\tvalid_1's rmse: 0.000436994\tvalid_1's RMSPE: 0.20087\n",
      "[14750]\ttraining's rmse: 0.000349295\ttraining's RMSPE: 0.16178\tvalid_1's rmse: 0.000436938\tvalid_1's RMSPE: 0.200844\n",
      "[15000]\ttraining's rmse: 0.000348232\ttraining's RMSPE: 0.161288\tvalid_1's rmse: 0.000436726\tvalid_1's RMSPE: 0.200746\n",
      "[15250]\ttraining's rmse: 0.000347255\ttraining's RMSPE: 0.160835\tvalid_1's rmse: 0.000436658\tvalid_1's RMSPE: 0.200715\n",
      "[15500]\ttraining's rmse: 0.000346199\ttraining's RMSPE: 0.160346\tvalid_1's rmse: 0.000436419\tvalid_1's RMSPE: 0.200605\n",
      "[15750]\ttraining's rmse: 0.000345272\ttraining's RMSPE: 0.159917\tvalid_1's rmse: 0.000436417\tvalid_1's RMSPE: 0.200605\n",
      "[16000]\ttraining's rmse: 0.000344259\ttraining's RMSPE: 0.159447\tvalid_1's rmse: 0.000436399\tvalid_1's RMSPE: 0.200596\n",
      "[16250]\ttraining's rmse: 0.000343317\ttraining's RMSPE: 0.159011\tvalid_1's rmse: 0.000436342\tvalid_1's RMSPE: 0.20057\n",
      "[16500]\ttraining's rmse: 0.000342343\ttraining's RMSPE: 0.15856\tvalid_1's rmse: 0.000436259\tvalid_1's RMSPE: 0.200532\n",
      "[16750]\ttraining's rmse: 0.000341413\ttraining's RMSPE: 0.158129\tvalid_1's rmse: 0.000436241\tvalid_1's RMSPE: 0.200524\n",
      "[17000]\ttraining's rmse: 0.00034045\ttraining's RMSPE: 0.157683\tvalid_1's rmse: 0.000436176\tvalid_1's RMSPE: 0.200494\n",
      "[17250]\ttraining's rmse: 0.000339552\ttraining's RMSPE: 0.157268\tvalid_1's rmse: 0.000436148\tvalid_1's RMSPE: 0.200481\n",
      "[17500]\ttraining's rmse: 0.000338601\ttraining's RMSPE: 0.156827\tvalid_1's rmse: 0.000435963\tvalid_1's RMSPE: 0.200396\n",
      "[17750]\ttraining's rmse: 0.000337736\ttraining's RMSPE: 0.156427\tvalid_1's rmse: 0.000435937\tvalid_1's RMSPE: 0.200384\n",
      "[18000]\ttraining's rmse: 0.000336826\ttraining's RMSPE: 0.156005\tvalid_1's rmse: 0.000435966\tvalid_1's RMSPE: 0.200397\n",
      "[18250]\ttraining's rmse: 0.000335951\ttraining's RMSPE: 0.155599\tvalid_1's rmse: 0.000435994\tvalid_1's RMSPE: 0.20041\n",
      "[18500]\ttraining's rmse: 0.000335046\ttraining's RMSPE: 0.15518\tvalid_1's rmse: 0.000435899\tvalid_1's RMSPE: 0.200366\n",
      "[18750]\ttraining's rmse: 0.000334156\ttraining's RMSPE: 0.154768\tvalid_1's rmse: 0.000435861\tvalid_1's RMSPE: 0.200349\n",
      "[19000]\ttraining's rmse: 0.000333237\ttraining's RMSPE: 0.154343\tvalid_1's rmse: 0.000435801\tvalid_1's RMSPE: 0.200322\n",
      "[19250]\ttraining's rmse: 0.000332296\ttraining's RMSPE: 0.153906\tvalid_1's rmse: 0.000435743\tvalid_1's RMSPE: 0.200295\n",
      "[19500]\ttraining's rmse: 0.00033141\ttraining's RMSPE: 0.153496\tvalid_1's rmse: 0.000435661\tvalid_1's RMSPE: 0.200257\n",
      "[19750]\ttraining's rmse: 0.000330539\ttraining's RMSPE: 0.153093\tvalid_1's rmse: 0.000435619\tvalid_1's RMSPE: 0.200238\n",
      "[20000]\ttraining's rmse: 0.000329654\ttraining's RMSPE: 0.152683\tvalid_1's rmse: 0.000435624\tvalid_1's RMSPE: 0.20024\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20000]\ttraining's rmse: 0.000329654\ttraining's RMSPE: 0.152683\tvalid_1's rmse: 0.000435624\tvalid_1's RMSPE: 0.20024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [34:23, 2063.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved \n",
      "==================================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's rmse: 0.000506499\ttraining's RMSPE: 0.234475\tvalid_1's rmse: 0.00051103\tvalid_1's RMSPE: 0.235954\n",
      "[500]\ttraining's rmse: 0.000476779\ttraining's RMSPE: 0.220717\tvalid_1's rmse: 0.000485548\tvalid_1's RMSPE: 0.224188\n",
      "[750]\ttraining's rmse: 0.000465832\ttraining's RMSPE: 0.215649\tvalid_1's rmse: 0.000478014\tvalid_1's RMSPE: 0.22071\n",
      "[1000]\ttraining's rmse: 0.000457638\ttraining's RMSPE: 0.211856\tvalid_1's rmse: 0.000472397\tvalid_1's RMSPE: 0.218116\n",
      "[1250]\ttraining's rmse: 0.000450808\ttraining's RMSPE: 0.208694\tvalid_1's rmse: 0.000467912\tvalid_1's RMSPE: 0.216045\n",
      "[1500]\ttraining's rmse: 0.000444631\ttraining's RMSPE: 0.205835\tvalid_1's rmse: 0.000463839\tvalid_1's RMSPE: 0.214165\n",
      "[1750]\ttraining's rmse: 0.000439566\ttraining's RMSPE: 0.20349\tvalid_1's rmse: 0.000460891\tvalid_1's RMSPE: 0.212804\n",
      "[2000]\ttraining's rmse: 0.000435044\ttraining's RMSPE: 0.201397\tvalid_1's rmse: 0.000458501\tvalid_1's RMSPE: 0.2117\n",
      "[2250]\ttraining's rmse: 0.000430948\ttraining's RMSPE: 0.1995\tvalid_1's rmse: 0.000456567\tvalid_1's RMSPE: 0.210807\n",
      "[2500]\ttraining's rmse: 0.0004273\ttraining's RMSPE: 0.197812\tvalid_1's rmse: 0.000454902\tvalid_1's RMSPE: 0.210039\n",
      "[2750]\ttraining's rmse: 0.000423871\ttraining's RMSPE: 0.196224\tvalid_1's rmse: 0.000453365\tvalid_1's RMSPE: 0.209329\n",
      "[3000]\ttraining's rmse: 0.000420789\ttraining's RMSPE: 0.194798\tvalid_1's rmse: 0.000452047\tvalid_1's RMSPE: 0.20872\n",
      "[3250]\ttraining's rmse: 0.000418228\ttraining's RMSPE: 0.193612\tvalid_1's rmse: 0.000451288\tvalid_1's RMSPE: 0.20837\n",
      "[3500]\ttraining's rmse: 0.000415802\ttraining's RMSPE: 0.192489\tvalid_1's rmse: 0.000450797\tvalid_1's RMSPE: 0.208143\n",
      "[3750]\ttraining's rmse: 0.00041319\ttraining's RMSPE: 0.191279\tvalid_1's rmse: 0.000449902\tvalid_1's RMSPE: 0.20773\n",
      "[4000]\ttraining's rmse: 0.000410745\ttraining's RMSPE: 0.190148\tvalid_1's rmse: 0.000448971\tvalid_1's RMSPE: 0.2073\n",
      "[4250]\ttraining's rmse: 0.000408661\ttraining's RMSPE: 0.189183\tvalid_1's rmse: 0.000448647\tvalid_1's RMSPE: 0.207151\n",
      "[4500]\ttraining's rmse: 0.000406573\ttraining's RMSPE: 0.188216\tvalid_1's rmse: 0.000448106\tvalid_1's RMSPE: 0.206901\n",
      "[4750]\ttraining's rmse: 0.000404481\ttraining's RMSPE: 0.187248\tvalid_1's rmse: 0.000447586\tvalid_1's RMSPE: 0.206661\n",
      "[5000]\ttraining's rmse: 0.000402512\ttraining's RMSPE: 0.186336\tvalid_1's rmse: 0.000447127\tvalid_1's RMSPE: 0.206449\n",
      "[5250]\ttraining's rmse: 0.000400607\ttraining's RMSPE: 0.185454\tvalid_1's rmse: 0.00044668\tvalid_1's RMSPE: 0.206242\n",
      "[5500]\ttraining's rmse: 0.000398831\ttraining's RMSPE: 0.184632\tvalid_1's rmse: 0.000446363\tvalid_1's RMSPE: 0.206096\n",
      "[5750]\ttraining's rmse: 0.000397198\ttraining's RMSPE: 0.183877\tvalid_1's rmse: 0.000446139\tvalid_1's RMSPE: 0.205993\n",
      "[6000]\ttraining's rmse: 0.000395391\ttraining's RMSPE: 0.18304\tvalid_1's rmse: 0.000445718\tvalid_1's RMSPE: 0.205798\n",
      "[6250]\ttraining's rmse: 0.000393654\ttraining's RMSPE: 0.182236\tvalid_1's rmse: 0.000445427\tvalid_1's RMSPE: 0.205664\n",
      "[6500]\ttraining's rmse: 0.000392055\ttraining's RMSPE: 0.181496\tvalid_1's rmse: 0.00044518\tvalid_1's RMSPE: 0.20555\n",
      "[6750]\ttraining's rmse: 0.000390495\ttraining's RMSPE: 0.180773\tvalid_1's rmse: 0.000445133\tvalid_1's RMSPE: 0.205528\n",
      "[7000]\ttraining's rmse: 0.000388863\ttraining's RMSPE: 0.180018\tvalid_1's rmse: 0.000444821\tvalid_1's RMSPE: 0.205384\n",
      "[7250]\ttraining's rmse: 0.000387307\ttraining's RMSPE: 0.179297\tvalid_1's rmse: 0.000444456\tvalid_1's RMSPE: 0.205215\n",
      "[7500]\ttraining's rmse: 0.00038568\ttraining's RMSPE: 0.178544\tvalid_1's rmse: 0.0004441\tvalid_1's RMSPE: 0.205051\n",
      "[7750]\ttraining's rmse: 0.000384221\ttraining's RMSPE: 0.177869\tvalid_1's rmse: 0.000444016\tvalid_1's RMSPE: 0.205012\n",
      "[8000]\ttraining's rmse: 0.000382664\ttraining's RMSPE: 0.177148\tvalid_1's rmse: 0.000443666\tvalid_1's RMSPE: 0.204851\n",
      "[8250]\ttraining's rmse: 0.000381166\ttraining's RMSPE: 0.176454\tvalid_1's rmse: 0.00044331\tvalid_1's RMSPE: 0.204686\n",
      "[8500]\ttraining's rmse: 0.00037977\ttraining's RMSPE: 0.175808\tvalid_1's rmse: 0.000443298\tvalid_1's RMSPE: 0.20468\n",
      "[8750]\ttraining's rmse: 0.000378314\ttraining's RMSPE: 0.175134\tvalid_1's rmse: 0.000443095\tvalid_1's RMSPE: 0.204587\n",
      "[9000]\ttraining's rmse: 0.000376931\ttraining's RMSPE: 0.174494\tvalid_1's rmse: 0.000443025\tvalid_1's RMSPE: 0.204555\n",
      "[9250]\ttraining's rmse: 0.000375618\ttraining's RMSPE: 0.173886\tvalid_1's rmse: 0.000442838\tvalid_1's RMSPE: 0.204468\n",
      "[9500]\ttraining's rmse: 0.000374317\ttraining's RMSPE: 0.173284\tvalid_1's rmse: 0.000442684\tvalid_1's RMSPE: 0.204397\n",
      "[9750]\ttraining's rmse: 0.000373014\ttraining's RMSPE: 0.172681\tvalid_1's rmse: 0.000442531\tvalid_1's RMSPE: 0.204327\n",
      "[10000]\ttraining's rmse: 0.000371755\ttraining's RMSPE: 0.172098\tvalid_1's rmse: 0.000442436\tvalid_1's RMSPE: 0.204283\n",
      "[10250]\ttraining's rmse: 0.000370473\ttraining's RMSPE: 0.171504\tvalid_1's rmse: 0.000442195\tvalid_1's RMSPE: 0.204172\n",
      "[10500]\ttraining's rmse: 0.000369158\ttraining's RMSPE: 0.170896\tvalid_1's rmse: 0.000441885\tvalid_1's RMSPE: 0.204028\n",
      "[10750]\ttraining's rmse: 0.000367878\ttraining's RMSPE: 0.170303\tvalid_1's rmse: 0.000441563\tvalid_1's RMSPE: 0.20388\n",
      "[11000]\ttraining's rmse: 0.000366579\ttraining's RMSPE: 0.169702\tvalid_1's rmse: 0.000441442\tvalid_1's RMSPE: 0.203824\n",
      "[11250]\ttraining's rmse: 0.000365405\ttraining's RMSPE: 0.169158\tvalid_1's rmse: 0.000441315\tvalid_1's RMSPE: 0.203765\n",
      "[11500]\ttraining's rmse: 0.000364185\ttraining's RMSPE: 0.168593\tvalid_1's rmse: 0.000441211\tvalid_1's RMSPE: 0.203717\n",
      "[11750]\ttraining's rmse: 0.000362997\ttraining's RMSPE: 0.168044\tvalid_1's rmse: 0.000441017\tvalid_1's RMSPE: 0.203628\n",
      "[12000]\ttraining's rmse: 0.000361855\ttraining's RMSPE: 0.167515\tvalid_1's rmse: 0.000440953\tvalid_1's RMSPE: 0.203598\n",
      "[12250]\ttraining's rmse: 0.0003607\ttraining's RMSPE: 0.16698\tvalid_1's rmse: 0.000440891\tvalid_1's RMSPE: 0.20357\n",
      "[12500]\ttraining's rmse: 0.000359554\ttraining's RMSPE: 0.166449\tvalid_1's rmse: 0.000440751\tvalid_1's RMSPE: 0.203505\n",
      "[12750]\ttraining's rmse: 0.000358389\ttraining's RMSPE: 0.16591\tvalid_1's rmse: 0.000440688\tvalid_1's RMSPE: 0.203475\n",
      "[13000]\ttraining's rmse: 0.000357326\ttraining's RMSPE: 0.165418\tvalid_1's rmse: 0.000440693\tvalid_1's RMSPE: 0.203478\n",
      "[13250]\ttraining's rmse: 0.000356135\ttraining's RMSPE: 0.164867\tvalid_1's rmse: 0.000440621\tvalid_1's RMSPE: 0.203445\n",
      "[13500]\ttraining's rmse: 0.000355107\ttraining's RMSPE: 0.164391\tvalid_1's rmse: 0.000440577\tvalid_1's RMSPE: 0.203424\n",
      "[13750]\ttraining's rmse: 0.000354049\ttraining's RMSPE: 0.163901\tvalid_1's rmse: 0.000440498\tvalid_1's RMSPE: 0.203388\n",
      "[14000]\ttraining's rmse: 0.00035299\ttraining's RMSPE: 0.163411\tvalid_1's rmse: 0.000440508\tvalid_1's RMSPE: 0.203392\n",
      "[14250]\ttraining's rmse: 0.000351966\ttraining's RMSPE: 0.162937\tvalid_1's rmse: 0.000440581\tvalid_1's RMSPE: 0.203426\n",
      "Early stopping, best iteration is:\n",
      "[13860]\ttraining's rmse: 0.000353584\ttraining's RMSPE: 0.163686\tvalid_1's rmse: 0.000440447\tvalid_1's RMSPE: 0.203364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [59:27, 1734.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved \n",
      "==================================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's rmse: 0.000506902\ttraining's RMSPE: 0.234632\tvalid_1's rmse: 0.00050749\tvalid_1's RMSPE: 0.234594\n",
      "[500]\ttraining's rmse: 0.00047701\ttraining's RMSPE: 0.220795\tvalid_1's rmse: 0.000480325\tvalid_1's RMSPE: 0.222037\n",
      "[750]\ttraining's rmse: 0.00046582\ttraining's RMSPE: 0.215616\tvalid_1's rmse: 0.000472083\tvalid_1's RMSPE: 0.218227\n",
      "[1000]\ttraining's rmse: 0.000457268\ttraining's RMSPE: 0.211657\tvalid_1's rmse: 0.000466008\tvalid_1's RMSPE: 0.215418\n",
      "[1250]\ttraining's rmse: 0.000450557\ttraining's RMSPE: 0.208551\tvalid_1's rmse: 0.00046179\tvalid_1's RMSPE: 0.213469\n",
      "[1500]\ttraining's rmse: 0.00044513\ttraining's RMSPE: 0.206039\tvalid_1's rmse: 0.000458825\tvalid_1's RMSPE: 0.212098\n",
      "[1750]\ttraining's rmse: 0.000440208\ttraining's RMSPE: 0.203761\tvalid_1's rmse: 0.000455937\tvalid_1's RMSPE: 0.210763\n",
      "[2000]\ttraining's rmse: 0.000435768\ttraining's RMSPE: 0.201706\tvalid_1's rmse: 0.000453478\tvalid_1's RMSPE: 0.209626\n",
      "[2250]\ttraining's rmse: 0.000431754\ttraining's RMSPE: 0.199848\tvalid_1's rmse: 0.00045137\tvalid_1's RMSPE: 0.208652\n",
      "[2500]\ttraining's rmse: 0.000428133\ttraining's RMSPE: 0.198171\tvalid_1's rmse: 0.000449845\tvalid_1's RMSPE: 0.207947\n",
      "[2750]\ttraining's rmse: 0.000424943\ttraining's RMSPE: 0.196695\tvalid_1's rmse: 0.000448593\tvalid_1's RMSPE: 0.207368\n",
      "[3000]\ttraining's rmse: 0.000421841\ttraining's RMSPE: 0.195259\tvalid_1's rmse: 0.000447234\tvalid_1's RMSPE: 0.20674\n",
      "[3250]\ttraining's rmse: 0.000419035\ttraining's RMSPE: 0.19396\tvalid_1's rmse: 0.000446558\tvalid_1's RMSPE: 0.206428\n",
      "[3500]\ttraining's rmse: 0.00041643\ttraining's RMSPE: 0.192755\tvalid_1's rmse: 0.000445726\tvalid_1's RMSPE: 0.206043\n",
      "[3750]\ttraining's rmse: 0.000413737\ttraining's RMSPE: 0.191508\tvalid_1's rmse: 0.000444406\tvalid_1's RMSPE: 0.205432\n",
      "[4000]\ttraining's rmse: 0.000411236\ttraining's RMSPE: 0.19035\tvalid_1's rmse: 0.000443329\tvalid_1's RMSPE: 0.204935\n",
      "[4250]\ttraining's rmse: 0.000409018\ttraining's RMSPE: 0.189324\tvalid_1's rmse: 0.000442555\tvalid_1's RMSPE: 0.204577\n",
      "[4500]\ttraining's rmse: 0.000406919\ttraining's RMSPE: 0.188352\tvalid_1's rmse: 0.00044194\tvalid_1's RMSPE: 0.204293\n",
      "[4750]\ttraining's rmse: 0.000404987\ttraining's RMSPE: 0.187458\tvalid_1's rmse: 0.00044169\tvalid_1's RMSPE: 0.204177\n",
      "[5000]\ttraining's rmse: 0.000402806\ttraining's RMSPE: 0.186448\tvalid_1's rmse: 0.000441174\tvalid_1's RMSPE: 0.203938\n",
      "[5250]\ttraining's rmse: 0.000400925\ttraining's RMSPE: 0.185578\tvalid_1's rmse: 0.000440831\tvalid_1's RMSPE: 0.20378\n",
      "[5500]\ttraining's rmse: 0.000399128\ttraining's RMSPE: 0.184746\tvalid_1's rmse: 0.000440578\tvalid_1's RMSPE: 0.203663\n",
      "[5750]\ttraining's rmse: 0.000397365\ttraining's RMSPE: 0.18393\tvalid_1's rmse: 0.0004403\tvalid_1's RMSPE: 0.203535\n",
      "[6000]\ttraining's rmse: 0.000395466\ttraining's RMSPE: 0.183051\tvalid_1's rmse: 0.000439717\tvalid_1's RMSPE: 0.203265\n",
      "[6250]\ttraining's rmse: 0.000393905\ttraining's RMSPE: 0.182328\tvalid_1's rmse: 0.000439701\tvalid_1's RMSPE: 0.203258\n",
      "[6500]\ttraining's rmse: 0.000392248\ttraining's RMSPE: 0.181561\tvalid_1's rmse: 0.000439405\tvalid_1's RMSPE: 0.203121\n",
      "[6750]\ttraining's rmse: 0.00039059\ttraining's RMSPE: 0.180794\tvalid_1's rmse: 0.000439121\tvalid_1's RMSPE: 0.20299\n",
      "[7000]\ttraining's rmse: 0.000388899\ttraining's RMSPE: 0.180011\tvalid_1's rmse: 0.000438734\tvalid_1's RMSPE: 0.202811\n",
      "[7250]\ttraining's rmse: 0.000387251\ttraining's RMSPE: 0.179248\tvalid_1's rmse: 0.000438339\tvalid_1's RMSPE: 0.202628\n",
      "[7500]\ttraining's rmse: 0.000385545\ttraining's RMSPE: 0.178458\tvalid_1's rmse: 0.000437899\tvalid_1's RMSPE: 0.202424\n",
      "[7750]\ttraining's rmse: 0.000384008\ttraining's RMSPE: 0.177747\tvalid_1's rmse: 0.000437531\tvalid_1's RMSPE: 0.202254\n",
      "[8000]\ttraining's rmse: 0.000382564\ttraining's RMSPE: 0.177079\tvalid_1's rmse: 0.000437344\tvalid_1's RMSPE: 0.202168\n",
      "[8250]\ttraining's rmse: 0.00038111\ttraining's RMSPE: 0.176406\tvalid_1's rmse: 0.000437208\tvalid_1's RMSPE: 0.202105\n",
      "[8500]\ttraining's rmse: 0.000379664\ttraining's RMSPE: 0.175737\tvalid_1's rmse: 0.000436914\tvalid_1's RMSPE: 0.201969\n",
      "[8750]\ttraining's rmse: 0.000378182\ttraining's RMSPE: 0.17505\tvalid_1's rmse: 0.000436454\tvalid_1's RMSPE: 0.201757\n",
      "[9000]\ttraining's rmse: 0.00037685\ttraining's RMSPE: 0.174434\tvalid_1's rmse: 0.000436297\tvalid_1's RMSPE: 0.201684\n",
      "[9250]\ttraining's rmse: 0.000375532\ttraining's RMSPE: 0.173824\tvalid_1's rmse: 0.000436323\tvalid_1's RMSPE: 0.201696\n",
      "[9500]\ttraining's rmse: 0.000374257\ttraining's RMSPE: 0.173234\tvalid_1's rmse: 0.000436145\tvalid_1's RMSPE: 0.201614\n",
      "[9750]\ttraining's rmse: 0.000372905\ttraining's RMSPE: 0.172608\tvalid_1's rmse: 0.000435923\tvalid_1's RMSPE: 0.201511\n",
      "[10000]\ttraining's rmse: 0.00037167\ttraining's RMSPE: 0.172036\tvalid_1's rmse: 0.000435918\tvalid_1's RMSPE: 0.201509\n",
      "[10250]\ttraining's rmse: 0.00037039\ttraining's RMSPE: 0.171444\tvalid_1's rmse: 0.000435723\tvalid_1's RMSPE: 0.201419\n",
      "[10500]\ttraining's rmse: 0.000369057\ttraining's RMSPE: 0.170827\tvalid_1's rmse: 0.000435521\tvalid_1's RMSPE: 0.201326\n",
      "[10750]\ttraining's rmse: 0.000367714\ttraining's RMSPE: 0.170205\tvalid_1's rmse: 0.000435276\tvalid_1's RMSPE: 0.201212\n",
      "[11000]\ttraining's rmse: 0.000366426\ttraining's RMSPE: 0.169609\tvalid_1's rmse: 0.000435144\tvalid_1's RMSPE: 0.201151\n",
      "[11250]\ttraining's rmse: 0.000365247\ttraining's RMSPE: 0.169063\tvalid_1's rmse: 0.000435124\tvalid_1's RMSPE: 0.201142\n",
      "[11500]\ttraining's rmse: 0.000364027\ttraining's RMSPE: 0.168498\tvalid_1's rmse: 0.000434861\tvalid_1's RMSPE: 0.20102\n",
      "[11750]\ttraining's rmse: 0.000362864\ttraining's RMSPE: 0.16796\tvalid_1's rmse: 0.000434811\tvalid_1's RMSPE: 0.200997\n",
      "[12000]\ttraining's rmse: 0.00036175\ttraining's RMSPE: 0.167444\tvalid_1's rmse: 0.000434816\tvalid_1's RMSPE: 0.200999\n",
      "[12250]\ttraining's rmse: 0.00036066\ttraining's RMSPE: 0.16694\tvalid_1's rmse: 0.000434808\tvalid_1's RMSPE: 0.200996\n",
      "[12500]\ttraining's rmse: 0.000359521\ttraining's RMSPE: 0.166413\tvalid_1's rmse: 0.00043467\tvalid_1's RMSPE: 0.200932\n",
      "[12750]\ttraining's rmse: 0.000358309\ttraining's RMSPE: 0.165852\tvalid_1's rmse: 0.000434431\tvalid_1's RMSPE: 0.200822\n",
      "[13000]\ttraining's rmse: 0.000357198\ttraining's RMSPE: 0.165338\tvalid_1's rmse: 0.000434367\tvalid_1's RMSPE: 0.200792\n",
      "[13250]\ttraining's rmse: 0.000356123\ttraining's RMSPE: 0.16484\tvalid_1's rmse: 0.000434296\tvalid_1's RMSPE: 0.200759\n",
      "[13500]\ttraining's rmse: 0.000354953\ttraining's RMSPE: 0.164298\tvalid_1's rmse: 0.000434167\tvalid_1's RMSPE: 0.2007\n",
      "[13750]\ttraining's rmse: 0.000353935\ttraining's RMSPE: 0.163827\tvalid_1's rmse: 0.00043412\tvalid_1's RMSPE: 0.200678\n",
      "[14000]\ttraining's rmse: 0.000352834\ttraining's RMSPE: 0.163317\tvalid_1's rmse: 0.000433922\tvalid_1's RMSPE: 0.200586\n",
      "[14250]\ttraining's rmse: 0.00035175\ttraining's RMSPE: 0.162816\tvalid_1's rmse: 0.000433796\tvalid_1's RMSPE: 0.200528\n",
      "[14500]\ttraining's rmse: 0.000350578\ttraining's RMSPE: 0.162273\tvalid_1's rmse: 0.000433575\tvalid_1's RMSPE: 0.200426\n",
      "[14750]\ttraining's rmse: 0.000349486\ttraining's RMSPE: 0.161768\tvalid_1's rmse: 0.000433583\tvalid_1's RMSPE: 0.20043\n",
      "[15000]\ttraining's rmse: 0.000348404\ttraining's RMSPE: 0.161267\tvalid_1's rmse: 0.000433406\tvalid_1's RMSPE: 0.200348\n",
      "[15250]\ttraining's rmse: 0.000347366\ttraining's RMSPE: 0.160787\tvalid_1's rmse: 0.000433312\tvalid_1's RMSPE: 0.200304\n",
      "[15500]\ttraining's rmse: 0.000346257\ttraining's RMSPE: 0.160273\tvalid_1's rmse: 0.000433243\tvalid_1's RMSPE: 0.200273\n",
      "[15750]\ttraining's rmse: 0.000345249\ttraining's RMSPE: 0.159807\tvalid_1's rmse: 0.000433305\tvalid_1's RMSPE: 0.200301\n",
      "Early stopping, best iteration is:\n",
      "[15454]\ttraining's rmse: 0.000346452\ttraining's RMSPE: 0.160364\tvalid_1's rmse: 0.000433181\tvalid_1's RMSPE: 0.200244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [1:27:09, 1701.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved \n",
      "==================================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's rmse: 0.000506192\ttraining's RMSPE: 0.234284\tvalid_1's rmse: 0.000516172\tvalid_1's RMSPE: 0.238781\n",
      "[500]\ttraining's rmse: 0.000476561\ttraining's RMSPE: 0.22057\tvalid_1's rmse: 0.000489301\tvalid_1's RMSPE: 0.226351\n",
      "[750]\ttraining's rmse: 0.000465389\ttraining's RMSPE: 0.215399\tvalid_1's rmse: 0.000481368\tvalid_1's RMSPE: 0.222681\n",
      "[1000]\ttraining's rmse: 0.000457293\ttraining's RMSPE: 0.211652\tvalid_1's rmse: 0.000475587\tvalid_1's RMSPE: 0.220007\n",
      "[1250]\ttraining's rmse: 0.000450675\ttraining's RMSPE: 0.208589\tvalid_1's rmse: 0.000471137\tvalid_1's RMSPE: 0.217948\n",
      "[1500]\ttraining's rmse: 0.000444967\ttraining's RMSPE: 0.205947\tvalid_1's rmse: 0.000467443\tvalid_1's RMSPE: 0.216239\n",
      "[1750]\ttraining's rmse: 0.000440201\ttraining's RMSPE: 0.203741\tvalid_1's rmse: 0.000464537\tvalid_1's RMSPE: 0.214895\n",
      "[2000]\ttraining's rmse: 0.000435764\ttraining's RMSPE: 0.201687\tvalid_1's rmse: 0.000461796\tvalid_1's RMSPE: 0.213627\n",
      "[2250]\ttraining's rmse: 0.000431745\ttraining's RMSPE: 0.199827\tvalid_1's rmse: 0.000459466\tvalid_1's RMSPE: 0.21255\n",
      "[2500]\ttraining's rmse: 0.000428102\ttraining's RMSPE: 0.198141\tvalid_1's rmse: 0.000457539\tvalid_1's RMSPE: 0.211658\n",
      "[2750]\ttraining's rmse: 0.000424847\ttraining's RMSPE: 0.196635\tvalid_1's rmse: 0.000456141\tvalid_1's RMSPE: 0.211011\n",
      "[3000]\ttraining's rmse: 0.000421768\ttraining's RMSPE: 0.19521\tvalid_1's rmse: 0.000454639\tvalid_1's RMSPE: 0.210316\n",
      "[3250]\ttraining's rmse: 0.000418999\ttraining's RMSPE: 0.193928\tvalid_1's rmse: 0.000453317\tvalid_1's RMSPE: 0.209705\n",
      "[3500]\ttraining's rmse: 0.000416445\ttraining's RMSPE: 0.192746\tvalid_1's rmse: 0.000452654\tvalid_1's RMSPE: 0.209398\n",
      "[3750]\ttraining's rmse: 0.000413949\ttraining's RMSPE: 0.19159\tvalid_1's rmse: 0.000451641\tvalid_1's RMSPE: 0.208929\n",
      "[4000]\ttraining's rmse: 0.000411726\ttraining's RMSPE: 0.190562\tvalid_1's rmse: 0.000451076\tvalid_1's RMSPE: 0.208668\n",
      "[4250]\ttraining's rmse: 0.000409375\ttraining's RMSPE: 0.189473\tvalid_1's rmse: 0.000450345\tvalid_1's RMSPE: 0.20833\n",
      "[4500]\ttraining's rmse: 0.000407225\ttraining's RMSPE: 0.188479\tvalid_1's rmse: 0.000449995\tvalid_1's RMSPE: 0.208168\n",
      "[4750]\ttraining's rmse: 0.00040523\ttraining's RMSPE: 0.187555\tvalid_1's rmse: 0.000449327\tvalid_1's RMSPE: 0.207859\n",
      "[5000]\ttraining's rmse: 0.000403189\ttraining's RMSPE: 0.186611\tvalid_1's rmse: 0.000448586\tvalid_1's RMSPE: 0.207516\n",
      "[5250]\ttraining's rmse: 0.000401396\ttraining's RMSPE: 0.185781\tvalid_1's rmse: 0.000448136\tvalid_1's RMSPE: 0.207308\n",
      "[5500]\ttraining's rmse: 0.000399399\ttraining's RMSPE: 0.184856\tvalid_1's rmse: 0.000447483\tvalid_1's RMSPE: 0.207006\n",
      "[5750]\ttraining's rmse: 0.00039746\ttraining's RMSPE: 0.183959\tvalid_1's rmse: 0.000446886\tvalid_1's RMSPE: 0.20673\n",
      "[6000]\ttraining's rmse: 0.00039574\ttraining's RMSPE: 0.183163\tvalid_1's rmse: 0.000446531\tvalid_1's RMSPE: 0.206566\n",
      "[6250]\ttraining's rmse: 0.000394152\ttraining's RMSPE: 0.182428\tvalid_1's rmse: 0.000446247\tvalid_1's RMSPE: 0.206434\n",
      "[6500]\ttraining's rmse: 0.000392449\ttraining's RMSPE: 0.18164\tvalid_1's rmse: 0.000445877\tvalid_1's RMSPE: 0.206263\n",
      "[6750]\ttraining's rmse: 0.000390692\ttraining's RMSPE: 0.180826\tvalid_1's rmse: 0.000445365\tvalid_1's RMSPE: 0.206026\n",
      "[7000]\ttraining's rmse: 0.000388995\ttraining's RMSPE: 0.180041\tvalid_1's rmse: 0.000444866\tvalid_1's RMSPE: 0.205795\n",
      "[7250]\ttraining's rmse: 0.000387405\ttraining's RMSPE: 0.179305\tvalid_1's rmse: 0.000444473\tvalid_1's RMSPE: 0.205614\n",
      "[7500]\ttraining's rmse: 0.000385854\ttraining's RMSPE: 0.178587\tvalid_1's rmse: 0.00044416\tvalid_1's RMSPE: 0.205469\n",
      "[7750]\ttraining's rmse: 0.000384409\ttraining's RMSPE: 0.177918\tvalid_1's rmse: 0.000443965\tvalid_1's RMSPE: 0.205379\n",
      "[8000]\ttraining's rmse: 0.000382809\ttraining's RMSPE: 0.177178\tvalid_1's rmse: 0.000443527\tvalid_1's RMSPE: 0.205176\n",
      "[8250]\ttraining's rmse: 0.000381327\ttraining's RMSPE: 0.176492\tvalid_1's rmse: 0.000443467\tvalid_1's RMSPE: 0.205148\n",
      "[8500]\ttraining's rmse: 0.000379888\ttraining's RMSPE: 0.175826\tvalid_1's rmse: 0.000443177\tvalid_1's RMSPE: 0.205014\n",
      "[8750]\ttraining's rmse: 0.000378443\ttraining's RMSPE: 0.175157\tvalid_1's rmse: 0.000442902\tvalid_1's RMSPE: 0.204887\n",
      "[9000]\ttraining's rmse: 0.000377086\ttraining's RMSPE: 0.174529\tvalid_1's rmse: 0.000442705\tvalid_1's RMSPE: 0.204795\n",
      "[9250]\ttraining's rmse: 0.000375769\ttraining's RMSPE: 0.173919\tvalid_1's rmse: 0.00044246\tvalid_1's RMSPE: 0.204682\n",
      "[9500]\ttraining's rmse: 0.000374377\ttraining's RMSPE: 0.173275\tvalid_1's rmse: 0.000442184\tvalid_1's RMSPE: 0.204555\n",
      "[9750]\ttraining's rmse: 0.000373048\ttraining's RMSPE: 0.17266\tvalid_1's rmse: 0.000441971\tvalid_1's RMSPE: 0.204456\n",
      "[10000]\ttraining's rmse: 0.000371732\ttraining's RMSPE: 0.172051\tvalid_1's rmse: 0.000441727\tvalid_1's RMSPE: 0.204343\n",
      "[10250]\ttraining's rmse: 0.000370488\ttraining's RMSPE: 0.171475\tvalid_1's rmse: 0.000441739\tvalid_1's RMSPE: 0.204349\n",
      "[10500]\ttraining's rmse: 0.000369152\ttraining's RMSPE: 0.170857\tvalid_1's rmse: 0.00044155\tvalid_1's RMSPE: 0.204261\n",
      "[10750]\ttraining's rmse: 0.000367923\ttraining's RMSPE: 0.170288\tvalid_1's rmse: 0.000441699\tvalid_1's RMSPE: 0.20433\n",
      "[11000]\ttraining's rmse: 0.000366622\ttraining's RMSPE: 0.169686\tvalid_1's rmse: 0.000441416\tvalid_1's RMSPE: 0.2042\n",
      "[11250]\ttraining's rmse: 0.000365374\ttraining's RMSPE: 0.169108\tvalid_1's rmse: 0.00044131\tvalid_1's RMSPE: 0.20415\n",
      "[11500]\ttraining's rmse: 0.00036416\ttraining's RMSPE: 0.168546\tvalid_1's rmse: 0.000441193\tvalid_1's RMSPE: 0.204096\n",
      "[11750]\ttraining's rmse: 0.00036294\ttraining's RMSPE: 0.167982\tvalid_1's rmse: 0.000441047\tvalid_1's RMSPE: 0.204029\n",
      "[12000]\ttraining's rmse: 0.00036185\ttraining's RMSPE: 0.167477\tvalid_1's rmse: 0.000441083\tvalid_1's RMSPE: 0.204045\n",
      "[12250]\ttraining's rmse: 0.000360651\ttraining's RMSPE: 0.166922\tvalid_1's rmse: 0.000440955\tvalid_1's RMSPE: 0.203986\n",
      "[12500]\ttraining's rmse: 0.000359508\ttraining's RMSPE: 0.166393\tvalid_1's rmse: 0.000440789\tvalid_1's RMSPE: 0.203909\n",
      "[12750]\ttraining's rmse: 0.000358474\ttraining's RMSPE: 0.165915\tvalid_1's rmse: 0.000440876\tvalid_1's RMSPE: 0.20395\n",
      "Early stopping, best iteration is:\n",
      "[12498]\ttraining's rmse: 0.000359518\ttraining's RMSPE: 0.166398\tvalid_1's rmse: 0.000440783\tvalid_1's RMSPE: 0.203906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [1:50:07, 1573.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved \n",
      "==================================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's rmse: 0.000506701\ttraining's RMSPE: 0.234451\tvalid_1's rmse: 0.000517509\tvalid_1's RMSPE: 0.240025\n",
      "[500]\ttraining's rmse: 0.000476885\ttraining's RMSPE: 0.220655\tvalid_1's rmse: 0.000491041\tvalid_1's RMSPE: 0.227749\n",
      "[750]\ttraining's rmse: 0.000465492\ttraining's RMSPE: 0.215384\tvalid_1's rmse: 0.000482864\tvalid_1's RMSPE: 0.223957\n",
      "[1000]\ttraining's rmse: 0.000457453\ttraining's RMSPE: 0.211665\tvalid_1's rmse: 0.000478658\tvalid_1's RMSPE: 0.222006\n",
      "[1250]\ttraining's rmse: 0.000450606\ttraining's RMSPE: 0.208496\tvalid_1's rmse: 0.000475107\tvalid_1's RMSPE: 0.220359\n",
      "[1500]\ttraining's rmse: 0.000445159\ttraining's RMSPE: 0.205976\tvalid_1's rmse: 0.000472101\tvalid_1's RMSPE: 0.218965\n",
      "[1750]\ttraining's rmse: 0.000440229\ttraining's RMSPE: 0.203695\tvalid_1's rmse: 0.000469369\tvalid_1's RMSPE: 0.217698\n",
      "[2000]\ttraining's rmse: 0.00043559\ttraining's RMSPE: 0.201548\tvalid_1's rmse: 0.000466816\tvalid_1's RMSPE: 0.216514\n",
      "[2250]\ttraining's rmse: 0.000431652\ttraining's RMSPE: 0.199726\tvalid_1's rmse: 0.000465362\tvalid_1's RMSPE: 0.215839\n",
      "[2500]\ttraining's rmse: 0.000428083\ttraining's RMSPE: 0.198075\tvalid_1's rmse: 0.000464268\tvalid_1's RMSPE: 0.215332\n",
      "[2750]\ttraining's rmse: 0.000424798\ttraining's RMSPE: 0.196555\tvalid_1's rmse: 0.000463114\tvalid_1's RMSPE: 0.214796\n",
      "[3000]\ttraining's rmse: 0.000421789\ttraining's RMSPE: 0.195162\tvalid_1's rmse: 0.000461933\tvalid_1's RMSPE: 0.214249\n",
      "[3250]\ttraining's rmse: 0.000418947\ttraining's RMSPE: 0.193847\tvalid_1's rmse: 0.000460633\tvalid_1's RMSPE: 0.213646\n",
      "[3500]\ttraining's rmse: 0.000416165\ttraining's RMSPE: 0.192561\tvalid_1's rmse: 0.000460255\tvalid_1's RMSPE: 0.21347\n",
      "[3750]\ttraining's rmse: 0.000413455\ttraining's RMSPE: 0.191306\tvalid_1's rmse: 0.000458989\tvalid_1's RMSPE: 0.212883\n",
      "[4000]\ttraining's rmse: 0.000411077\ttraining's RMSPE: 0.190206\tvalid_1's rmse: 0.000458847\tvalid_1's RMSPE: 0.212817\n",
      "[4250]\ttraining's rmse: 0.000408989\ttraining's RMSPE: 0.18924\tvalid_1's rmse: 0.000458707\tvalid_1's RMSPE: 0.212753\n",
      "[4500]\ttraining's rmse: 0.000406733\ttraining's RMSPE: 0.188196\tvalid_1's rmse: 0.000458196\tvalid_1's RMSPE: 0.212516\n",
      "[4750]\ttraining's rmse: 0.000404612\ttraining's RMSPE: 0.187215\tvalid_1's rmse: 0.000458332\tvalid_1's RMSPE: 0.212579\n",
      "[5000]\ttraining's rmse: 0.00040267\ttraining's RMSPE: 0.186316\tvalid_1's rmse: 0.000458054\tvalid_1's RMSPE: 0.21245\n",
      "[5250]\ttraining's rmse: 0.000400821\ttraining's RMSPE: 0.18546\tvalid_1's rmse: 0.000457623\tvalid_1's RMSPE: 0.21225\n",
      "[5500]\ttraining's rmse: 0.00039893\ttraining's RMSPE: 0.184586\tvalid_1's rmse: 0.000457211\tvalid_1's RMSPE: 0.212059\n",
      "[5750]\ttraining's rmse: 0.000397118\ttraining's RMSPE: 0.183747\tvalid_1's rmse: 0.000456836\tvalid_1's RMSPE: 0.211885\n",
      "[6000]\ttraining's rmse: 0.000395315\ttraining's RMSPE: 0.182913\tvalid_1's rmse: 0.000456609\tvalid_1's RMSPE: 0.21178\n",
      "[6250]\ttraining's rmse: 0.0003937\ttraining's RMSPE: 0.182166\tvalid_1's rmse: 0.000456427\tvalid_1's RMSPE: 0.211695\n",
      "[6500]\ttraining's rmse: 0.000391964\ttraining's RMSPE: 0.181362\tvalid_1's rmse: 0.00045612\tvalid_1's RMSPE: 0.211553\n",
      "[6750]\ttraining's rmse: 0.000390228\ttraining's RMSPE: 0.180559\tvalid_1's rmse: 0.000455569\tvalid_1's RMSPE: 0.211297\n",
      "[7000]\ttraining's rmse: 0.000388538\ttraining's RMSPE: 0.179777\tvalid_1's rmse: 0.000455438\tvalid_1's RMSPE: 0.211237\n",
      "[7250]\ttraining's rmse: 0.000386957\ttraining's RMSPE: 0.179046\tvalid_1's rmse: 0.000455425\tvalid_1's RMSPE: 0.211231\n",
      "[7500]\ttraining's rmse: 0.000385504\ttraining's RMSPE: 0.178373\tvalid_1's rmse: 0.00045534\tvalid_1's RMSPE: 0.211191\n",
      "[7750]\ttraining's rmse: 0.000384061\ttraining's RMSPE: 0.177706\tvalid_1's rmse: 0.000455077\tvalid_1's RMSPE: 0.211069\n",
      "[8000]\ttraining's rmse: 0.000382574\ttraining's RMSPE: 0.177018\tvalid_1's rmse: 0.000454956\tvalid_1's RMSPE: 0.211013\n",
      "[8250]\ttraining's rmse: 0.000380988\ttraining's RMSPE: 0.176284\tvalid_1's rmse: 0.000454576\tvalid_1's RMSPE: 0.210837\n",
      "[8500]\ttraining's rmse: 0.000379612\ttraining's RMSPE: 0.175647\tvalid_1's rmse: 0.000454485\tvalid_1's RMSPE: 0.210795\n",
      "[8750]\ttraining's rmse: 0.000378258\ttraining's RMSPE: 0.175021\tvalid_1's rmse: 0.000454628\tvalid_1's RMSPE: 0.210861\n",
      "[9000]\ttraining's rmse: 0.000376881\ttraining's RMSPE: 0.174384\tvalid_1's rmse: 0.000454538\tvalid_1's RMSPE: 0.210819\n",
      "Early stopping, best iteration is:\n",
      "[8526]\ttraining's rmse: 0.000379465\ttraining's RMSPE: 0.175579\tvalid_1's rmse: 0.000454462\tvalid_1's RMSPE: 0.210784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [2:06:03, 1351.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved \n",
      "==================================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's rmse: 0.000506006\ttraining's RMSPE: 0.23415\tvalid_1's rmse: 0.00051498\tvalid_1's RMSPE: 0.238671\n",
      "[500]\ttraining's rmse: 0.000476438\ttraining's RMSPE: 0.220467\tvalid_1's rmse: 0.000488654\tvalid_1's RMSPE: 0.22647\n",
      "[750]\ttraining's rmse: 0.000465265\ttraining's RMSPE: 0.215297\tvalid_1's rmse: 0.000479911\tvalid_1's RMSPE: 0.222418\n",
      "[1000]\ttraining's rmse: 0.000456954\ttraining's RMSPE: 0.211451\tvalid_1's rmse: 0.000473675\tvalid_1's RMSPE: 0.219528\n",
      "[1250]\ttraining's rmse: 0.000450015\ttraining's RMSPE: 0.208241\tvalid_1's rmse: 0.000468704\tvalid_1's RMSPE: 0.217224\n",
      "[1500]\ttraining's rmse: 0.00044461\ttraining's RMSPE: 0.205739\tvalid_1's rmse: 0.000465425\tvalid_1's RMSPE: 0.215704\n",
      "[1750]\ttraining's rmse: 0.000439654\ttraining's RMSPE: 0.203446\tvalid_1's rmse: 0.000462156\tvalid_1's RMSPE: 0.214189\n",
      "[2000]\ttraining's rmse: 0.000435223\ttraining's RMSPE: 0.201395\tvalid_1's rmse: 0.00045974\tvalid_1's RMSPE: 0.213069\n",
      "[2250]\ttraining's rmse: 0.000431466\ttraining's RMSPE: 0.199657\tvalid_1's rmse: 0.000457868\tvalid_1's RMSPE: 0.212202\n",
      "[2500]\ttraining's rmse: 0.000427811\ttraining's RMSPE: 0.197966\tvalid_1's rmse: 0.00045601\tvalid_1's RMSPE: 0.211341\n",
      "[2750]\ttraining's rmse: 0.000424545\ttraining's RMSPE: 0.196454\tvalid_1's rmse: 0.000454556\tvalid_1's RMSPE: 0.210667\n",
      "[3000]\ttraining's rmse: 0.000421322\ttraining's RMSPE: 0.194963\tvalid_1's rmse: 0.000452942\tvalid_1's RMSPE: 0.209919\n",
      "[3250]\ttraining's rmse: 0.000418441\ttraining's RMSPE: 0.19363\tvalid_1's rmse: 0.000451476\tvalid_1's RMSPE: 0.20924\n",
      "[3500]\ttraining's rmse: 0.00041583\ttraining's RMSPE: 0.192421\tvalid_1's rmse: 0.000450345\tvalid_1's RMSPE: 0.208715\n",
      "[3750]\ttraining's rmse: 0.000413429\ttraining's RMSPE: 0.191311\tvalid_1's rmse: 0.000449358\tvalid_1's RMSPE: 0.208258\n",
      "[4000]\ttraining's rmse: 0.000411234\ttraining's RMSPE: 0.190295\tvalid_1's rmse: 0.00044856\tvalid_1's RMSPE: 0.207888\n",
      "[4250]\ttraining's rmse: 0.000408769\ttraining's RMSPE: 0.189154\tvalid_1's rmse: 0.000447471\tvalid_1's RMSPE: 0.207383\n",
      "[4500]\ttraining's rmse: 0.000406573\ttraining's RMSPE: 0.188138\tvalid_1's rmse: 0.000446671\tvalid_1's RMSPE: 0.207012\n",
      "[4750]\ttraining's rmse: 0.000404591\ttraining's RMSPE: 0.187221\tvalid_1's rmse: 0.000446132\tvalid_1's RMSPE: 0.206763\n",
      "[5000]\ttraining's rmse: 0.000402561\ttraining's RMSPE: 0.186281\tvalid_1's rmse: 0.000445537\tvalid_1's RMSPE: 0.206487\n",
      "[5250]\ttraining's rmse: 0.000400471\ttraining's RMSPE: 0.185314\tvalid_1's rmse: 0.000444758\tvalid_1's RMSPE: 0.206126\n",
      "[5500]\ttraining's rmse: 0.000398571\ttraining's RMSPE: 0.184435\tvalid_1's rmse: 0.000444186\tvalid_1's RMSPE: 0.205861\n",
      "[5750]\ttraining's rmse: 0.000396807\ttraining's RMSPE: 0.183619\tvalid_1's rmse: 0.000443759\tvalid_1's RMSPE: 0.205663\n",
      "[6000]\ttraining's rmse: 0.000394924\ttraining's RMSPE: 0.182747\tvalid_1's rmse: 0.000443063\tvalid_1's RMSPE: 0.20534\n",
      "[6250]\ttraining's rmse: 0.000393275\ttraining's RMSPE: 0.181984\tvalid_1's rmse: 0.000442672\tvalid_1's RMSPE: 0.205159\n",
      "[6500]\ttraining's rmse: 0.00039156\ttraining's RMSPE: 0.181191\tvalid_1's rmse: 0.000442146\tvalid_1's RMSPE: 0.204916\n",
      "[6750]\ttraining's rmse: 0.000389996\ttraining's RMSPE: 0.180467\tvalid_1's rmse: 0.000441846\tvalid_1's RMSPE: 0.204777\n",
      "[7000]\ttraining's rmse: 0.000388383\ttraining's RMSPE: 0.179721\tvalid_1's rmse: 0.000441457\tvalid_1's RMSPE: 0.204596\n",
      "[7250]\ttraining's rmse: 0.000386776\ttraining's RMSPE: 0.178977\tvalid_1's rmse: 0.00044109\tvalid_1's RMSPE: 0.204426\n",
      "[7500]\ttraining's rmse: 0.000385263\ttraining's RMSPE: 0.178277\tvalid_1's rmse: 0.000440812\tvalid_1's RMSPE: 0.204297\n",
      "[7750]\ttraining's rmse: 0.00038385\ttraining's RMSPE: 0.177623\tvalid_1's rmse: 0.000440643\tvalid_1's RMSPE: 0.204219\n",
      "[8000]\ttraining's rmse: 0.000382367\ttraining's RMSPE: 0.176937\tvalid_1's rmse: 0.000440282\tvalid_1's RMSPE: 0.204051\n",
      "[8250]\ttraining's rmse: 0.000380866\ttraining's RMSPE: 0.176243\tvalid_1's rmse: 0.000439942\tvalid_1's RMSPE: 0.203894\n",
      "[8500]\ttraining's rmse: 0.00037919\ttraining's RMSPE: 0.175467\tvalid_1's rmse: 0.000439397\tvalid_1's RMSPE: 0.203641\n",
      "[8750]\ttraining's rmse: 0.000377886\ttraining's RMSPE: 0.174863\tvalid_1's rmse: 0.000439286\tvalid_1's RMSPE: 0.20359\n",
      "[9000]\ttraining's rmse: 0.000376546\ttraining's RMSPE: 0.174243\tvalid_1's rmse: 0.000439125\tvalid_1's RMSPE: 0.203516\n",
      "[9250]\ttraining's rmse: 0.000375193\ttraining's RMSPE: 0.173617\tvalid_1's rmse: 0.000438841\tvalid_1's RMSPE: 0.203383\n",
      "[9500]\ttraining's rmse: 0.000373862\ttraining's RMSPE: 0.173001\tvalid_1's rmse: 0.000438601\tvalid_1's RMSPE: 0.203273\n",
      "[9750]\ttraining's rmse: 0.000372543\ttraining's RMSPE: 0.172391\tvalid_1's rmse: 0.000438358\tvalid_1's RMSPE: 0.20316\n",
      "[10000]\ttraining's rmse: 0.000371231\ttraining's RMSPE: 0.171784\tvalid_1's rmse: 0.000438136\tvalid_1's RMSPE: 0.203057\n",
      "[10250]\ttraining's rmse: 0.000370045\ttraining's RMSPE: 0.171235\tvalid_1's rmse: 0.00043806\tvalid_1's RMSPE: 0.203022\n",
      "[10500]\ttraining's rmse: 0.000368681\ttraining's RMSPE: 0.170604\tvalid_1's rmse: 0.000437735\tvalid_1's RMSPE: 0.202871\n",
      "[10750]\ttraining's rmse: 0.000367347\ttraining's RMSPE: 0.169987\tvalid_1's rmse: 0.000437523\tvalid_1's RMSPE: 0.202773\n",
      "[11000]\ttraining's rmse: 0.000366126\ttraining's RMSPE: 0.169422\tvalid_1's rmse: 0.00043738\tvalid_1's RMSPE: 0.202707\n",
      "[11250]\ttraining's rmse: 0.000364913\ttraining's RMSPE: 0.16886\tvalid_1's rmse: 0.000437238\tvalid_1's RMSPE: 0.202641\n",
      "[11500]\ttraining's rmse: 0.00036377\ttraining's RMSPE: 0.168331\tvalid_1's rmse: 0.000437056\tvalid_1's RMSPE: 0.202556\n",
      "[11750]\ttraining's rmse: 0.000362618\ttraining's RMSPE: 0.167798\tvalid_1's rmse: 0.000436928\tvalid_1's RMSPE: 0.202497\n",
      "[12000]\ttraining's rmse: 0.000361374\ttraining's RMSPE: 0.167222\tvalid_1's rmse: 0.000436689\tvalid_1's RMSPE: 0.202386\n",
      "[12250]\ttraining's rmse: 0.000360191\ttraining's RMSPE: 0.166675\tvalid_1's rmse: 0.000436517\tvalid_1's RMSPE: 0.202307\n",
      "[12500]\ttraining's rmse: 0.000359118\ttraining's RMSPE: 0.166179\tvalid_1's rmse: 0.000436449\tvalid_1's RMSPE: 0.202275\n",
      "[12750]\ttraining's rmse: 0.000357888\ttraining's RMSPE: 0.165609\tvalid_1's rmse: 0.000436162\tvalid_1's RMSPE: 0.202142\n",
      "[13000]\ttraining's rmse: 0.000356758\ttraining's RMSPE: 0.165087\tvalid_1's rmse: 0.000435934\tvalid_1's RMSPE: 0.202036\n",
      "[13250]\ttraining's rmse: 0.000355594\ttraining's RMSPE: 0.164548\tvalid_1's rmse: 0.000435735\tvalid_1's RMSPE: 0.201944\n",
      "[13500]\ttraining's rmse: 0.000354497\ttraining's RMSPE: 0.16404\tvalid_1's rmse: 0.000435641\tvalid_1's RMSPE: 0.201901\n",
      "[13750]\ttraining's rmse: 0.000353386\ttraining's RMSPE: 0.163526\tvalid_1's rmse: 0.000435427\tvalid_1's RMSPE: 0.201801\n",
      "[14000]\ttraining's rmse: 0.000352308\ttraining's RMSPE: 0.163027\tvalid_1's rmse: 0.000435308\tvalid_1's RMSPE: 0.201746\n",
      "[14250]\ttraining's rmse: 0.000351219\ttraining's RMSPE: 0.162523\tvalid_1's rmse: 0.000435097\tvalid_1's RMSPE: 0.201648\n",
      "[14500]\ttraining's rmse: 0.000350143\ttraining's RMSPE: 0.162026\tvalid_1's rmse: 0.000435022\tvalid_1's RMSPE: 0.201614\n",
      "[14750]\ttraining's rmse: 0.000349121\ttraining's RMSPE: 0.161553\tvalid_1's rmse: 0.000434916\tvalid_1's RMSPE: 0.201564\n",
      "[15000]\ttraining's rmse: 0.000348147\ttraining's RMSPE: 0.161102\tvalid_1's rmse: 0.000434898\tvalid_1's RMSPE: 0.201556\n",
      "[15250]\ttraining's rmse: 0.00034719\ttraining's RMSPE: 0.160659\tvalid_1's rmse: 0.000434919\tvalid_1's RMSPE: 0.201566\n",
      "[15500]\ttraining's rmse: 0.00034621\ttraining's RMSPE: 0.160206\tvalid_1's rmse: 0.000434843\tvalid_1's RMSPE: 0.201531\n",
      "[15750]\ttraining's rmse: 0.000345155\ttraining's RMSPE: 0.159718\tvalid_1's rmse: 0.000434632\tvalid_1's RMSPE: 0.201433\n",
      "[16000]\ttraining's rmse: 0.000344224\ttraining's RMSPE: 0.159287\tvalid_1's rmse: 0.000434735\tvalid_1's RMSPE: 0.201481\n",
      "[16250]\ttraining's rmse: 0.000343222\ttraining's RMSPE: 0.158823\tvalid_1's rmse: 0.000434623\tvalid_1's RMSPE: 0.201429\n",
      "[16500]\ttraining's rmse: 0.000342248\ttraining's RMSPE: 0.158372\tvalid_1's rmse: 0.000434534\tvalid_1's RMSPE: 0.201387\n",
      "[16750]\ttraining's rmse: 0.000341245\ttraining's RMSPE: 0.157908\tvalid_1's rmse: 0.000434381\tvalid_1's RMSPE: 0.201317\n",
      "[17000]\ttraining's rmse: 0.000340278\ttraining's RMSPE: 0.157461\tvalid_1's rmse: 0.000434265\tvalid_1's RMSPE: 0.201263\n",
      "[17250]\ttraining's rmse: 0.000339346\ttraining's RMSPE: 0.157029\tvalid_1's rmse: 0.000434211\tvalid_1's RMSPE: 0.201238\n",
      "[17500]\ttraining's rmse: 0.000338386\ttraining's RMSPE: 0.156585\tvalid_1's rmse: 0.000434124\tvalid_1's RMSPE: 0.201197\n",
      "[17750]\ttraining's rmse: 0.000337453\ttraining's RMSPE: 0.156153\tvalid_1's rmse: 0.000434018\tvalid_1's RMSPE: 0.201149\n",
      "[18000]\ttraining's rmse: 0.00033651\ttraining's RMSPE: 0.155717\tvalid_1's rmse: 0.000433953\tvalid_1's RMSPE: 0.201118\n",
      "[18250]\ttraining's rmse: 0.000335623\ttraining's RMSPE: 0.155307\tvalid_1's rmse: 0.000433904\tvalid_1's RMSPE: 0.201096\n",
      "[18500]\ttraining's rmse: 0.000334715\ttraining's RMSPE: 0.154886\tvalid_1's rmse: 0.000433789\tvalid_1's RMSPE: 0.201042\n",
      "[18750]\ttraining's rmse: 0.000333807\ttraining's RMSPE: 0.154466\tvalid_1's rmse: 0.000433741\tvalid_1's RMSPE: 0.20102\n",
      "[19000]\ttraining's rmse: 0.000332905\ttraining's RMSPE: 0.154049\tvalid_1's rmse: 0.00043367\tvalid_1's RMSPE: 0.200987\n",
      "[19250]\ttraining's rmse: 0.00033199\ttraining's RMSPE: 0.153625\tvalid_1's rmse: 0.000433672\tvalid_1's RMSPE: 0.200988\n",
      "[19500]\ttraining's rmse: 0.000331119\ttraining's RMSPE: 0.153222\tvalid_1's rmse: 0.000433598\tvalid_1's RMSPE: 0.200954\n",
      "[19750]\ttraining's rmse: 0.000330235\ttraining's RMSPE: 0.152813\tvalid_1's rmse: 0.000433594\tvalid_1's RMSPE: 0.200952\n",
      "[20000]\ttraining's rmse: 0.000329366\ttraining's RMSPE: 0.152411\tvalid_1's rmse: 0.000433523\tvalid_1's RMSPE: 0.200919\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20000]\ttraining's rmse: 0.000329366\ttraining's RMSPE: 0.152411\tvalid_1's rmse: 0.000433523\tvalid_1's RMSPE: 0.200919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [2:40:46, 1599.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved \n",
      "==================================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's rmse: 0.000506866\ttraining's RMSPE: 0.234484\tvalid_1's rmse: 0.000510832\tvalid_1's RMSPE: 0.23732\n",
      "[500]\ttraining's rmse: 0.000477131\ttraining's RMSPE: 0.220728\tvalid_1's rmse: 0.000482996\tvalid_1's RMSPE: 0.224388\n",
      "[750]\ttraining's rmse: 0.000465908\ttraining's RMSPE: 0.215537\tvalid_1's rmse: 0.000475508\tvalid_1's RMSPE: 0.22091\n",
      "[1000]\ttraining's rmse: 0.000457532\ttraining's RMSPE: 0.211662\tvalid_1's rmse: 0.000470073\tvalid_1's RMSPE: 0.218384\n",
      "[1250]\ttraining's rmse: 0.000450733\ttraining's RMSPE: 0.208517\tvalid_1's rmse: 0.000465833\tvalid_1's RMSPE: 0.216415\n",
      "[1500]\ttraining's rmse: 0.000444971\ttraining's RMSPE: 0.205851\tvalid_1's rmse: 0.000462566\tvalid_1's RMSPE: 0.214897\n",
      "[1750]\ttraining's rmse: 0.000439908\ttraining's RMSPE: 0.203509\tvalid_1's rmse: 0.000460218\tvalid_1's RMSPE: 0.213806\n",
      "[2000]\ttraining's rmse: 0.000435543\ttraining's RMSPE: 0.201489\tvalid_1's rmse: 0.000458754\tvalid_1's RMSPE: 0.213126\n",
      "[2250]\ttraining's rmse: 0.000431825\ttraining's RMSPE: 0.199769\tvalid_1's rmse: 0.000457054\tvalid_1's RMSPE: 0.212337\n",
      "[2500]\ttraining's rmse: 0.000427973\ttraining's RMSPE: 0.197987\tvalid_1's rmse: 0.000455912\tvalid_1's RMSPE: 0.211806\n",
      "[2750]\ttraining's rmse: 0.000424694\ttraining's RMSPE: 0.196471\tvalid_1's rmse: 0.000454441\tvalid_1's RMSPE: 0.211122\n",
      "[3000]\ttraining's rmse: 0.000421837\ttraining's RMSPE: 0.195149\tvalid_1's rmse: 0.00045326\tvalid_1's RMSPE: 0.210574\n",
      "[3250]\ttraining's rmse: 0.000418806\ttraining's RMSPE: 0.193746\tvalid_1's rmse: 0.000451732\tvalid_1's RMSPE: 0.209864\n",
      "[3500]\ttraining's rmse: 0.000416345\ttraining's RMSPE: 0.192608\tvalid_1's rmse: 0.000450979\tvalid_1's RMSPE: 0.209514\n",
      "[3750]\ttraining's rmse: 0.000413827\ttraining's RMSPE: 0.191443\tvalid_1's rmse: 0.00045071\tvalid_1's RMSPE: 0.209389\n",
      "[4000]\ttraining's rmse: 0.000411459\ttraining's RMSPE: 0.190348\tvalid_1's rmse: 0.000450947\tvalid_1's RMSPE: 0.209499\n",
      "Early stopping, best iteration is:\n",
      "[3700]\ttraining's rmse: 0.000414344\ttraining's RMSPE: 0.191682\tvalid_1's rmse: 0.000450364\tvalid_1's RMSPE: 0.209228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [2:49:03, 1239.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved \n",
      "==================================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's rmse: 0.000506246\ttraining's RMSPE: 0.234331\tvalid_1's rmse: 0.000518271\tvalid_1's RMSPE: 0.239548\n",
      "[500]\ttraining's rmse: 0.000476605\ttraining's RMSPE: 0.220611\tvalid_1's rmse: 0.000490361\tvalid_1's RMSPE: 0.226648\n",
      "[750]\ttraining's rmse: 0.000465261\ttraining's RMSPE: 0.21536\tvalid_1's rmse: 0.000481851\tvalid_1's RMSPE: 0.222715\n",
      "[1000]\ttraining's rmse: 0.000456814\ttraining's RMSPE: 0.21145\tvalid_1's rmse: 0.000476651\tvalid_1's RMSPE: 0.220311\n",
      "[1250]\ttraining's rmse: 0.000449755\ttraining's RMSPE: 0.208183\tvalid_1's rmse: 0.000472056\tvalid_1's RMSPE: 0.218188\n",
      "[1500]\ttraining's rmse: 0.000444153\ttraining's RMSPE: 0.20559\tvalid_1's rmse: 0.000468444\tvalid_1's RMSPE: 0.216518\n",
      "[1750]\ttraining's rmse: 0.000438852\ttraining's RMSPE: 0.203136\tvalid_1's rmse: 0.000465808\tvalid_1's RMSPE: 0.2153\n",
      "[2000]\ttraining's rmse: 0.000434727\ttraining's RMSPE: 0.201226\tvalid_1's rmse: 0.00046448\tvalid_1's RMSPE: 0.214686\n",
      "[2250]\ttraining's rmse: 0.000430779\ttraining's RMSPE: 0.199399\tvalid_1's rmse: 0.000462824\tvalid_1's RMSPE: 0.21392\n",
      "[2500]\ttraining's rmse: 0.000427312\ttraining's RMSPE: 0.197794\tvalid_1's rmse: 0.000461215\tvalid_1's RMSPE: 0.213177\n",
      "[2750]\ttraining's rmse: 0.000424091\ttraining's RMSPE: 0.196303\tvalid_1's rmse: 0.000459854\tvalid_1's RMSPE: 0.212548\n",
      "[3000]\ttraining's rmse: 0.00042089\ttraining's RMSPE: 0.194822\tvalid_1's rmse: 0.000458499\tvalid_1's RMSPE: 0.211921\n",
      "[3250]\ttraining's rmse: 0.000418244\ttraining's RMSPE: 0.193597\tvalid_1's rmse: 0.000457882\tvalid_1's RMSPE: 0.211636\n",
      "[3500]\ttraining's rmse: 0.000415543\ttraining's RMSPE: 0.192347\tvalid_1's rmse: 0.000456823\tvalid_1's RMSPE: 0.211147\n",
      "[3750]\ttraining's rmse: 0.000413061\ttraining's RMSPE: 0.191198\tvalid_1's rmse: 0.000455838\tvalid_1's RMSPE: 0.210692\n",
      "[4000]\ttraining's rmse: 0.000410353\ttraining's RMSPE: 0.189944\tvalid_1's rmse: 0.000454699\tvalid_1's RMSPE: 0.210165\n",
      "[4250]\ttraining's rmse: 0.000408185\ttraining's RMSPE: 0.18894\tvalid_1's rmse: 0.000453911\tvalid_1's RMSPE: 0.209801\n",
      "[4500]\ttraining's rmse: 0.000406201\ttraining's RMSPE: 0.188022\tvalid_1's rmse: 0.00045366\tvalid_1's RMSPE: 0.209685\n",
      "[4750]\ttraining's rmse: 0.000403959\ttraining's RMSPE: 0.186984\tvalid_1's rmse: 0.000452836\tvalid_1's RMSPE: 0.209304\n",
      "[5000]\ttraining's rmse: 0.000402114\ttraining's RMSPE: 0.186131\tvalid_1's rmse: 0.000452922\tvalid_1's RMSPE: 0.209344\n",
      "[5250]\ttraining's rmse: 0.000400377\ttraining's RMSPE: 0.185326\tvalid_1's rmse: 0.000452724\tvalid_1's RMSPE: 0.209252\n",
      "[5500]\ttraining's rmse: 0.000398443\ttraining's RMSPE: 0.184431\tvalid_1's rmse: 0.000452534\tvalid_1's RMSPE: 0.209164\n",
      "[5750]\ttraining's rmse: 0.000396719\ttraining's RMSPE: 0.183633\tvalid_1's rmse: 0.000452187\tvalid_1's RMSPE: 0.209004\n",
      "[6000]\ttraining's rmse: 0.00039488\ttraining's RMSPE: 0.182782\tvalid_1's rmse: 0.000451783\tvalid_1's RMSPE: 0.208817\n",
      "[6250]\ttraining's rmse: 0.000393119\ttraining's RMSPE: 0.181967\tvalid_1's rmse: 0.000451385\tvalid_1's RMSPE: 0.208633\n",
      "[6500]\ttraining's rmse: 0.000391503\ttraining's RMSPE: 0.181219\tvalid_1's rmse: 0.000451198\tvalid_1's RMSPE: 0.208547\n",
      "[6750]\ttraining's rmse: 0.000389805\ttraining's RMSPE: 0.180433\tvalid_1's rmse: 0.000450932\tvalid_1's RMSPE: 0.208424\n",
      "[7000]\ttraining's rmse: 0.000388141\ttraining's RMSPE: 0.179662\tvalid_1's rmse: 0.000450694\tvalid_1's RMSPE: 0.208314\n",
      "[7250]\ttraining's rmse: 0.000386636\ttraining's RMSPE: 0.178966\tvalid_1's rmse: 0.000450445\tvalid_1's RMSPE: 0.208199\n",
      "[7500]\ttraining's rmse: 0.000385133\ttraining's RMSPE: 0.17827\tvalid_1's rmse: 0.0004504\tvalid_1's RMSPE: 0.208178\n",
      "[7750]\ttraining's rmse: 0.000383686\ttraining's RMSPE: 0.1776\tvalid_1's rmse: 0.000450423\tvalid_1's RMSPE: 0.208189\n",
      "[8000]\ttraining's rmse: 0.00038218\ttraining's RMSPE: 0.176903\tvalid_1's rmse: 0.000450066\tvalid_1's RMSPE: 0.208024\n",
      "[8250]\ttraining's rmse: 0.000380705\ttraining's RMSPE: 0.176221\tvalid_1's rmse: 0.000450041\tvalid_1's RMSPE: 0.208012\n",
      "[8500]\ttraining's rmse: 0.00037924\ttraining's RMSPE: 0.175542\tvalid_1's rmse: 0.000449999\tvalid_1's RMSPE: 0.207992\n",
      "Early stopping, best iteration is:\n",
      "[8229]\ttraining's rmse: 0.000380868\ttraining's RMSPE: 0.176296\tvalid_1's rmse: 0.000449841\tvalid_1's RMSPE: 0.20792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [3:05:20, 1155.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved \n",
      "==================================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's rmse: 0.000505998\ttraining's RMSPE: 0.234189\tvalid_1's rmse: 0.000517995\tvalid_1's RMSPE: 0.239668\n",
      "[500]\ttraining's rmse: 0.000476271\ttraining's RMSPE: 0.220431\tvalid_1's rmse: 0.000489371\tvalid_1's RMSPE: 0.226424\n",
      "[750]\ttraining's rmse: 0.000465114\ttraining's RMSPE: 0.215267\tvalid_1's rmse: 0.000480584\tvalid_1's RMSPE: 0.222359\n",
      "[1000]\ttraining's rmse: 0.000456767\ttraining's RMSPE: 0.211404\tvalid_1's rmse: 0.000474542\tvalid_1's RMSPE: 0.219563\n",
      "[1250]\ttraining's rmse: 0.00045005\ttraining's RMSPE: 0.208295\tvalid_1's rmse: 0.000469811\tvalid_1's RMSPE: 0.217374\n",
      "[1500]\ttraining's rmse: 0.000444079\ttraining's RMSPE: 0.205532\tvalid_1's rmse: 0.000465869\tvalid_1's RMSPE: 0.21555\n",
      "[1750]\ttraining's rmse: 0.000438961\ttraining's RMSPE: 0.203163\tvalid_1's rmse: 0.000462508\tvalid_1's RMSPE: 0.213995\n",
      "[2000]\ttraining's rmse: 0.000434618\ttraining's RMSPE: 0.201153\tvalid_1's rmse: 0.000460081\tvalid_1's RMSPE: 0.212872\n",
      "[2250]\ttraining's rmse: 0.000430825\ttraining's RMSPE: 0.199397\tvalid_1's rmse: 0.000458031\tvalid_1's RMSPE: 0.211924\n",
      "[2500]\ttraining's rmse: 0.000427257\ttraining's RMSPE: 0.197746\tvalid_1's rmse: 0.00045636\tvalid_1's RMSPE: 0.211151\n",
      "[2750]\ttraining's rmse: 0.000423904\ttraining's RMSPE: 0.196194\tvalid_1's rmse: 0.000454864\tvalid_1's RMSPE: 0.210458\n",
      "[3000]\ttraining's rmse: 0.000420857\ttraining's RMSPE: 0.194784\tvalid_1's rmse: 0.000453453\tvalid_1's RMSPE: 0.209806\n",
      "[3250]\ttraining's rmse: 0.000418181\ttraining's RMSPE: 0.193545\tvalid_1's rmse: 0.000452449\tvalid_1's RMSPE: 0.209341\n",
      "[3500]\ttraining's rmse: 0.000415496\ttraining's RMSPE: 0.192303\tvalid_1's rmse: 0.000451342\tvalid_1's RMSPE: 0.208829\n",
      "[3750]\ttraining's rmse: 0.000413076\ttraining's RMSPE: 0.191183\tvalid_1's rmse: 0.000450433\tvalid_1's RMSPE: 0.208408\n",
      "[4000]\ttraining's rmse: 0.000410574\ttraining's RMSPE: 0.190025\tvalid_1's rmse: 0.000449363\tvalid_1's RMSPE: 0.207913\n",
      "[4250]\ttraining's rmse: 0.000408272\ttraining's RMSPE: 0.188959\tvalid_1's rmse: 0.000448586\tvalid_1's RMSPE: 0.207554\n",
      "[4500]\ttraining's rmse: 0.000406215\ttraining's RMSPE: 0.188007\tvalid_1's rmse: 0.000448003\tvalid_1's RMSPE: 0.207284\n",
      "[4750]\ttraining's rmse: 0.000404036\ttraining's RMSPE: 0.186999\tvalid_1's rmse: 0.000447325\tvalid_1's RMSPE: 0.20697\n",
      "[5000]\ttraining's rmse: 0.000402158\ttraining's RMSPE: 0.18613\tvalid_1's rmse: 0.000446931\tvalid_1's RMSPE: 0.206788\n",
      "[5250]\ttraining's rmse: 0.000400252\ttraining's RMSPE: 0.185247\tvalid_1's rmse: 0.000446324\tvalid_1's RMSPE: 0.206507\n",
      "[5500]\ttraining's rmse: 0.000398398\ttraining's RMSPE: 0.184389\tvalid_1's rmse: 0.000445749\tvalid_1's RMSPE: 0.206241\n",
      "[5750]\ttraining's rmse: 0.000396699\ttraining's RMSPE: 0.183603\tvalid_1's rmse: 0.000445582\tvalid_1's RMSPE: 0.206164\n",
      "[6000]\ttraining's rmse: 0.000394952\ttraining's RMSPE: 0.182795\tvalid_1's rmse: 0.000445092\tvalid_1's RMSPE: 0.205937\n",
      "[6250]\ttraining's rmse: 0.000393218\ttraining's RMSPE: 0.181992\tvalid_1's rmse: 0.000444596\tvalid_1's RMSPE: 0.205707\n",
      "[6500]\ttraining's rmse: 0.000391478\ttraining's RMSPE: 0.181187\tvalid_1's rmse: 0.000444119\tvalid_1's RMSPE: 0.205487\n",
      "[6750]\ttraining's rmse: 0.000389924\ttraining's RMSPE: 0.180467\tvalid_1's rmse: 0.000443848\tvalid_1's RMSPE: 0.205362\n",
      "[7000]\ttraining's rmse: 0.000388356\ttraining's RMSPE: 0.179741\tvalid_1's rmse: 0.000443568\tvalid_1's RMSPE: 0.205232\n",
      "[7250]\ttraining's rmse: 0.000386736\ttraining's RMSPE: 0.178992\tvalid_1's rmse: 0.000443204\tvalid_1's RMSPE: 0.205063\n",
      "[7500]\ttraining's rmse: 0.000385253\ttraining's RMSPE: 0.178306\tvalid_1's rmse: 0.000442976\tvalid_1's RMSPE: 0.204958\n",
      "[7750]\ttraining's rmse: 0.000383842\ttraining's RMSPE: 0.177652\tvalid_1's rmse: 0.000442805\tvalid_1's RMSPE: 0.204879\n",
      "[8000]\ttraining's rmse: 0.000382395\ttraining's RMSPE: 0.176983\tvalid_1's rmse: 0.000442526\tvalid_1's RMSPE: 0.20475\n",
      "[8250]\ttraining's rmse: 0.000380962\ttraining's RMSPE: 0.176319\tvalid_1's rmse: 0.000442349\tvalid_1's RMSPE: 0.204668\n",
      "[8500]\ttraining's rmse: 0.000379617\ttraining's RMSPE: 0.175697\tvalid_1's rmse: 0.000442122\tvalid_1's RMSPE: 0.204563\n",
      "[8750]\ttraining's rmse: 0.000378078\ttraining's RMSPE: 0.174985\tvalid_1's rmse: 0.000441793\tvalid_1's RMSPE: 0.204411\n",
      "[9000]\ttraining's rmse: 0.000376773\ttraining's RMSPE: 0.174381\tvalid_1's rmse: 0.000441631\tvalid_1's RMSPE: 0.204336\n",
      "[9250]\ttraining's rmse: 0.000375213\ttraining's RMSPE: 0.173659\tvalid_1's rmse: 0.000441128\tvalid_1's RMSPE: 0.204103\n",
      "[9500]\ttraining's rmse: 0.000373885\ttraining's RMSPE: 0.173044\tvalid_1's rmse: 0.000440939\tvalid_1's RMSPE: 0.204016\n",
      "[9750]\ttraining's rmse: 0.000372627\ttraining's RMSPE: 0.172462\tvalid_1's rmse: 0.000440712\tvalid_1's RMSPE: 0.203911\n",
      "[10000]\ttraining's rmse: 0.000371363\ttraining's RMSPE: 0.171877\tvalid_1's rmse: 0.000440568\tvalid_1's RMSPE: 0.203844\n",
      "[10250]\ttraining's rmse: 0.000370074\ttraining's RMSPE: 0.17128\tvalid_1's rmse: 0.000440381\tvalid_1's RMSPE: 0.203757\n",
      "[10500]\ttraining's rmse: 0.000368848\ttraining's RMSPE: 0.170713\tvalid_1's rmse: 0.000440288\tvalid_1's RMSPE: 0.203715\n",
      "[10750]\ttraining's rmse: 0.000367596\ttraining's RMSPE: 0.170134\tvalid_1's rmse: 0.000440078\tvalid_1's RMSPE: 0.203617\n",
      "[11000]\ttraining's rmse: 0.000366366\ttraining's RMSPE: 0.169564\tvalid_1's rmse: 0.000439951\tvalid_1's RMSPE: 0.203558\n",
      "[11250]\ttraining's rmse: 0.000365115\ttraining's RMSPE: 0.168985\tvalid_1's rmse: 0.000439747\tvalid_1's RMSPE: 0.203464\n",
      "[11500]\ttraining's rmse: 0.000363909\ttraining's RMSPE: 0.168427\tvalid_1's rmse: 0.000439583\tvalid_1's RMSPE: 0.203388\n",
      "[11750]\ttraining's rmse: 0.000362601\ttraining's RMSPE: 0.167822\tvalid_1's rmse: 0.000439278\tvalid_1's RMSPE: 0.203247\n",
      "[12000]\ttraining's rmse: 0.000361426\ttraining's RMSPE: 0.167278\tvalid_1's rmse: 0.000439111\tvalid_1's RMSPE: 0.20317\n",
      "[12250]\ttraining's rmse: 0.000360321\ttraining's RMSPE: 0.166766\tvalid_1's rmse: 0.000438994\tvalid_1's RMSPE: 0.203115\n",
      "[12500]\ttraining's rmse: 0.000359134\ttraining's RMSPE: 0.166217\tvalid_1's rmse: 0.000438885\tvalid_1's RMSPE: 0.203065\n",
      "[12750]\ttraining's rmse: 0.000357989\ttraining's RMSPE: 0.165687\tvalid_1's rmse: 0.000438739\tvalid_1's RMSPE: 0.202998\n",
      "[13000]\ttraining's rmse: 0.000356848\ttraining's RMSPE: 0.165159\tvalid_1's rmse: 0.000438617\tvalid_1's RMSPE: 0.202941\n",
      "[13250]\ttraining's rmse: 0.000355759\ttraining's RMSPE: 0.164655\tvalid_1's rmse: 0.000438504\tvalid_1's RMSPE: 0.202889\n",
      "[13500]\ttraining's rmse: 0.000354642\ttraining's RMSPE: 0.164138\tvalid_1's rmse: 0.0004383\tvalid_1's RMSPE: 0.202794\n",
      "[13750]\ttraining's rmse: 0.000353598\ttraining's RMSPE: 0.163654\tvalid_1's rmse: 0.000438249\tvalid_1's RMSPE: 0.202771\n",
      "[14000]\ttraining's rmse: 0.000352563\ttraining's RMSPE: 0.163175\tvalid_1's rmse: 0.000438248\tvalid_1's RMSPE: 0.20277\n",
      "[14250]\ttraining's rmse: 0.000351532\ttraining's RMSPE: 0.162698\tvalid_1's rmse: 0.000438117\tvalid_1's RMSPE: 0.20271\n",
      "[14500]\ttraining's rmse: 0.000350435\ttraining's RMSPE: 0.162191\tvalid_1's rmse: 0.00043798\tvalid_1's RMSPE: 0.202647\n",
      "[14750]\ttraining's rmse: 0.000349416\ttraining's RMSPE: 0.161719\tvalid_1's rmse: 0.000437897\tvalid_1's RMSPE: 0.202608\n",
      "[15000]\ttraining's rmse: 0.000348397\ttraining's RMSPE: 0.161247\tvalid_1's rmse: 0.000437791\tvalid_1's RMSPE: 0.202559\n",
      "[15250]\ttraining's rmse: 0.0003474\ttraining's RMSPE: 0.160786\tvalid_1's rmse: 0.000437672\tvalid_1's RMSPE: 0.202504\n",
      "[15500]\ttraining's rmse: 0.000346358\ttraining's RMSPE: 0.160304\tvalid_1's rmse: 0.000437576\tvalid_1's RMSPE: 0.202459\n",
      "[15750]\ttraining's rmse: 0.000345308\ttraining's RMSPE: 0.159818\tvalid_1's rmse: 0.000437509\tvalid_1's RMSPE: 0.202429\n",
      "[16000]\ttraining's rmse: 0.000344293\ttraining's RMSPE: 0.159348\tvalid_1's rmse: 0.000437395\tvalid_1's RMSPE: 0.202376\n",
      "[16250]\ttraining's rmse: 0.000343278\ttraining's RMSPE: 0.158878\tvalid_1's rmse: 0.000437303\tvalid_1's RMSPE: 0.202333\n",
      "[16500]\ttraining's rmse: 0.000342287\ttraining's RMSPE: 0.15842\tvalid_1's rmse: 0.00043711\tvalid_1's RMSPE: 0.202244\n",
      "[16750]\ttraining's rmse: 0.000341364\ttraining's RMSPE: 0.157992\tvalid_1's rmse: 0.00043711\tvalid_1's RMSPE: 0.202244\n",
      "[17000]\ttraining's rmse: 0.000340405\ttraining's RMSPE: 0.157549\tvalid_1's rmse: 0.000437043\tvalid_1's RMSPE: 0.202213\n",
      "[17250]\ttraining's rmse: 0.000339455\ttraining's RMSPE: 0.157109\tvalid_1's rmse: 0.000437085\tvalid_1's RMSPE: 0.202233\n",
      "[17500]\ttraining's rmse: 0.000338525\ttraining's RMSPE: 0.156679\tvalid_1's rmse: 0.000436989\tvalid_1's RMSPE: 0.202188\n",
      "[17750]\ttraining's rmse: 0.000337558\ttraining's RMSPE: 0.156231\tvalid_1's rmse: 0.000436885\tvalid_1's RMSPE: 0.20214\n",
      "[18000]\ttraining's rmse: 0.000336649\ttraining's RMSPE: 0.15581\tvalid_1's rmse: 0.000436795\tvalid_1's RMSPE: 0.202098\n",
      "[18250]\ttraining's rmse: 0.000335762\ttraining's RMSPE: 0.1554\tvalid_1's rmse: 0.000436772\tvalid_1's RMSPE: 0.202088\n",
      "[18500]\ttraining's rmse: 0.000334867\ttraining's RMSPE: 0.154985\tvalid_1's rmse: 0.000436704\tvalid_1's RMSPE: 0.202056\n",
      "[18750]\ttraining's rmse: 0.000333972\ttraining's RMSPE: 0.154571\tvalid_1's rmse: 0.000436611\tvalid_1's RMSPE: 0.202013\n",
      "[19000]\ttraining's rmse: 0.000333068\ttraining's RMSPE: 0.154153\tvalid_1's rmse: 0.000436579\tvalid_1's RMSPE: 0.201998\n",
      "[19250]\ttraining's rmse: 0.000332216\ttraining's RMSPE: 0.153759\tvalid_1's rmse: 0.000436515\tvalid_1's RMSPE: 0.201969\n",
      "[19500]\ttraining's rmse: 0.000331316\ttraining's RMSPE: 0.153342\tvalid_1's rmse: 0.000436442\tvalid_1's RMSPE: 0.201935\n",
      "[19750]\ttraining's rmse: 0.00033038\ttraining's RMSPE: 0.152909\tvalid_1's rmse: 0.000436321\tvalid_1's RMSPE: 0.201879\n",
      "[20000]\ttraining's rmse: 0.000329488\ttraining's RMSPE: 0.152496\tvalid_1's rmse: 0.000436209\tvalid_1's RMSPE: 0.201827\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20000]\ttraining's rmse: 0.000329488\ttraining's RMSPE: 0.152496\tvalid_1's rmse: 0.000436209\tvalid_1's RMSPE: 0.201827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [3:39:50, 1441.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved \n",
      "==================================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[250]\ttraining's rmse: 0.000507019\ttraining's RMSPE: 0.234524\tvalid_1's rmse: 0.000530268\tvalid_1's RMSPE: 0.246639\n",
      "[500]\ttraining's rmse: 0.000477364\ttraining's RMSPE: 0.220808\tvalid_1's rmse: 0.000503793\tvalid_1's RMSPE: 0.234325\n",
      "[750]\ttraining's rmse: 0.00046611\ttraining's RMSPE: 0.215602\tvalid_1's rmse: 0.000495245\tvalid_1's RMSPE: 0.230349\n",
      "[1000]\ttraining's rmse: 0.00045784\ttraining's RMSPE: 0.211777\tvalid_1's rmse: 0.000489402\tvalid_1's RMSPE: 0.227631\n",
      "[1250]\ttraining's rmse: 0.000451332\ttraining's RMSPE: 0.208766\tvalid_1's rmse: 0.000485325\tvalid_1's RMSPE: 0.225735\n",
      "[1500]\ttraining's rmse: 0.000445382\ttraining's RMSPE: 0.206014\tvalid_1's rmse: 0.000481365\tvalid_1's RMSPE: 0.223893\n",
      "[1750]\ttraining's rmse: 0.000440095\ttraining's RMSPE: 0.203568\tvalid_1's rmse: 0.000477737\tvalid_1's RMSPE: 0.222206\n",
      "[2000]\ttraining's rmse: 0.00043582\ttraining's RMSPE: 0.201591\tvalid_1's rmse: 0.000475504\tvalid_1's RMSPE: 0.221167\n",
      "[2250]\ttraining's rmse: 0.000432073\ttraining's RMSPE: 0.199858\tvalid_1's rmse: 0.000474261\tvalid_1's RMSPE: 0.220589\n",
      "[2500]\ttraining's rmse: 0.00042845\ttraining's RMSPE: 0.198182\tvalid_1's rmse: 0.000472548\tvalid_1's RMSPE: 0.219792\n",
      "[2750]\ttraining's rmse: 0.000425329\ttraining's RMSPE: 0.196738\tvalid_1's rmse: 0.000471225\tvalid_1's RMSPE: 0.219177\n",
      "[3000]\ttraining's rmse: 0.000422354\ttraining's RMSPE: 0.195362\tvalid_1's rmse: 0.000470489\tvalid_1's RMSPE: 0.218834\n",
      "[3250]\ttraining's rmse: 0.000419407\ttraining's RMSPE: 0.193999\tvalid_1's rmse: 0.000469411\tvalid_1's RMSPE: 0.218333\n",
      "[3500]\ttraining's rmse: 0.000416556\ttraining's RMSPE: 0.19268\tvalid_1's rmse: 0.000468255\tvalid_1's RMSPE: 0.217795\n",
      "[3750]\ttraining's rmse: 0.000414315\ttraining's RMSPE: 0.191643\tvalid_1's rmse: 0.000467909\tvalid_1's RMSPE: 0.217634\n",
      "[4000]\ttraining's rmse: 0.000411938\ttraining's RMSPE: 0.190544\tvalid_1's rmse: 0.000467412\tvalid_1's RMSPE: 0.217403\n",
      "[4250]\ttraining's rmse: 0.00040968\ttraining's RMSPE: 0.1895\tvalid_1's rmse: 0.00046684\tvalid_1's RMSPE: 0.217137\n",
      "[4500]\ttraining's rmse: 0.000407634\ttraining's RMSPE: 0.188553\tvalid_1's rmse: 0.00046738\tvalid_1's RMSPE: 0.217389\n",
      "[4750]\ttraining's rmse: 0.000405601\ttraining's RMSPE: 0.187613\tvalid_1's rmse: 0.000467169\tvalid_1's RMSPE: 0.21729\n",
      "Early stopping, best iteration is:\n",
      "[4286]\ttraining's rmse: 0.000409371\ttraining's RMSPE: 0.189357\tvalid_1's rmse: 0.000466723\tvalid_1's RMSPE: 0.217083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [3:49:00, 1374.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved \n",
      "==================================\n",
      "0.20561931255122717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oof_df = util.fit_model(params,X_train,y_train,features,cats=['stock_id'],n_fold=10,seed=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
