{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm \n",
    "from glob import glob\n",
    "import joblib\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dir = '../input/optiver-realized-volatility-prediction'\n",
    "# model_dir = '../input/optiver-realized-volatility-prediction'\n",
    "input_dir = '../data'\n",
    "output_dir = './'\n",
    "model_dir = '../model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_book(stock_id=0, data_type='train'):\n",
    "    \"\"\"加载 book 数据\n",
    "    \"\"\"\n",
    "    book_df = pd.read_parquet(\n",
    "        os.path.join(input_dir,\n",
    "                     'book_{}.parquet/stock_id={}'.format(data_type,\n",
    "                                                          stock_id)))\n",
    "    book_df['stock_id'] = stock_id\n",
    "    book_df['stock_id'] = book_df['stock_id'].astype(np.int8)\n",
    "    book_df['seconds_in_bucket'] = book_df['seconds_in_bucket'].astype(\n",
    "        np.int32)\n",
    "\n",
    "    return book_df\n",
    "\n",
    "\n",
    "def load_trade(stock_id=0, data_type='train'):\n",
    "    \"\"\"加载 trade 数据\n",
    "    \"\"\"\n",
    "    trade_df = pd.read_parquet(\n",
    "        os.path.join(\n",
    "            input_dir,\n",
    "            'trade_{}.parquet/stock_id={}'.format(data_type, stock_id)))\n",
    "    trade_df['stock_id'] = stock_id\n",
    "    trade_df['stock_id'] = trade_df['stock_id'].astype(np.int8)\n",
    "    trade_df['order_count'] = trade_df['order_count'].astype(np.int32)\n",
    "    trade_df['seconds_in_bucket'] = trade_df['seconds_in_bucket'].astype(\n",
    "        np.int32)\n",
    "\n",
    "    return trade_df\n",
    "def log_return(list_stock_prices):\n",
    "    \"\"\"收益率\n",
    "    \"\"\"\n",
    "    return np.log(list_stock_prices).diff()\n",
    "\n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    \"\"\"波动率\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "\n",
    "def fix_jsonerr(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    df.columns = [\n",
    "        \"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in df.columns\n",
    "    ]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征工程\n",
    "def feature_row(book):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # book_wap1 生成标签\n",
    "    for i in [\n",
    "            1,\n",
    "            2,\n",
    "    ]:\n",
    "        # wap\n",
    "        book[f'book_wap{i}'] = (book[f'bid_price{i}'] * book[f'ask_size{i}'] +\n",
    "                                book[f'ask_price{i}'] *\n",
    "                                book[f'bid_size{i}']) / (book[f'bid_size{i}'] +\n",
    "                                                         book[f'ask_size{i}'])\n",
    "\n",
    "    # mean wap\n",
    "    book['book_wap_mean'] = (book['book_wap1'] + book['book_wap2']) / 2\n",
    "\n",
    "    # wap diff\n",
    "    book['book_wap_diff'] = book['book_wap1'] - book['book_wap2']\n",
    "\n",
    "    # other orderbook features\n",
    "    book['book_price_spread'] = (book['ask_price1'] - book['bid_price1']) / (\n",
    "        book['ask_price1'] + book['bid_price1'])\n",
    "    book['book_bid_spread'] = book['bid_price1'] - book['bid_price2']\n",
    "    book['book_ask_spread'] = book['ask_price1'] - book['ask_price2']\n",
    "    book['book_total_volume'] = book['ask_size1'] + book['ask_size2'] + book[\n",
    "        'bid_size1'] + book['bid_size2']\n",
    "    book['book_volume_imbalance'] = (book['ask_size1'] + book['ask_size2']) - (\n",
    "        book['bid_size1'] + book['bid_size2'])\n",
    "    return book\n",
    "\n",
    "\n",
    "def feature_agg(book, trade):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # 聚合生成特征\n",
    "    book_feats = book.columns[book.columns.str.startswith('book_')].tolist()\n",
    "    trade_feats = ['price', 'size', 'order_count', 'seconds_in_bucket']\n",
    "\n",
    "    trade = trade.groupby(['time_id', 'stock_id'])[trade_feats].agg(\n",
    "        ['sum', 'mean', 'std', 'max', 'min']).reset_index()\n",
    "\n",
    "    book = book.groupby(['time_id', 'stock_id'])[book_feats].agg(\n",
    "        [lambda x: realized_volatility(log_return(x))]).reset_index()\n",
    "\n",
    "    # 修改特征名称\n",
    "    book.columns = [\"\".join(col).strip() for col in book.columns.values]\n",
    "    trade.columns = [\"\".join(col).strip() for col in trade.columns.values]\n",
    "    df_ret = book.merge(trade, how='left', on=['time_id', 'stock_id'])\n",
    "    return df_ret\n",
    "\n",
    "def gen_data_test(stock_id=0):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    book = load_book(stock_id, 'test')\n",
    "    trade = load_trade(stock_id, 'test')\n",
    "\n",
    "    book = book.sort_values(by=['time_id', 'seconds_in_bucket'])\n",
    "    trade = trade.sort_values(by=['time_id', 'seconds_in_bucket'])\n",
    "\n",
    "    book = feature_row(book)\n",
    "\n",
    "    df_ret = feature_agg(book, trade)\n",
    "\n",
    "    return df_ret\n",
    "\n",
    "def gen_data_multi(stock_lst, data_type='train'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    with Pool(cpu_count()) as p:\n",
    "        if data_type == 'train':\n",
    "            feature_dfs = list(\n",
    "                tqdm(p.imap(gen_data_train, stock_lst), total=len(stock_lst)))\n",
    "        if data_type == 'test':\n",
    "            feature_dfs = list(\n",
    "                tqdm(p.imap(gen_data_test, stock_lst), total=len(stock_lst)))\n",
    "    df_ret = pd.concat(feature_dfs)\n",
    "    return df_ret\n",
    "\n",
    "def gen_data_encoding(df_ret, df_label, data_type='train'):\n",
    "    \"\"\"\n",
    "    test 不使用自己数据的 stock_id encoding\n",
    "    \"\"\"\n",
    "\n",
    "    # 对 stock_id 进行 encoding\n",
    "    vol_feats = [f for f in df_ret.columns if ('lambda' in f) & ('wap' in f)]\n",
    "    if data_type == 'train':\n",
    "        # agg\n",
    "        stock_df = df_ret.groupby('stock_id')[vol_feats].agg([\n",
    "            'mean',\n",
    "            'std',\n",
    "            'max',\n",
    "            'min',\n",
    "        ]).reset_index()\n",
    "\n",
    "        # fix column names\n",
    "        stock_df.columns = ['stock_id'] + [\n",
    "            f'{f}_stock' for f in stock_df.columns.values.tolist()[1:]\n",
    "        ]\n",
    "        stock_df = fix_jsonerr(stock_df)\n",
    "\n",
    "    # 对 time_id 进行 encoding\n",
    "    time_df = df_ret.groupby('time_id')[vol_feats].agg([\n",
    "        'mean',\n",
    "        'std',\n",
    "        'max',\n",
    "        'min',\n",
    "    ]).reset_index()\n",
    "    time_df.columns = ['time_id'] + [\n",
    "        f'{f}_time' for f in time_df.columns.values.tolist()[1:]\n",
    "    ]\n",
    "\n",
    "    # merge\n",
    "    df_ret = df_ret.merge(time_df, how='left', on='time_id')\n",
    "\n",
    "    # make sure to fix json error for lighgbm\n",
    "    df_ret = fix_jsonerr(df_ret)\n",
    "    # out\n",
    "    if data_type == 'train':\n",
    "        df_ret = df_ret.merge(stock_df, how='left', on='stock_id').merge(\n",
    "            df_label, how='left',\n",
    "            on=['stock_id', 'time_id']).replace([np.inf, -np.inf],\n",
    "                                                np.nan).fillna(method='ffill')\n",
    "        return df_ret\n",
    "    if data_type == 'test':\n",
    "        stock_df = pd.read_pickle(os.path.join(input_dir,'20210805.pkl'))\n",
    "        df_ret = df_ret.merge(stock_df, how='left', on= ['stock_id']).replace([np.inf, -np.inf],\n",
    "                                                np.nan).fillna(method='ffill')\n",
    "        return df_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lst = glob(os.path.join(input_dir,'book_test.parquet/*'))\n",
    "stock_lst = [os.path.basename(path).split('=')[-1] for path in path_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  9.54it/s]\n"
     ]
    }
   ],
   "source": [
    "df_ret_test = gen_data_multi(stock_lst, data_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_test = gen_data_encoding(df_ret_test, None, data_type = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = pd.read_pickle(os.path.join(features_name_dir,'features_name.pkl')).values.reshape(-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:02,  4.39it/s]\n"
     ]
    }
   ],
   "source": [
    "y_preds = np.zeros(len(df_all_test))\n",
    "model_lst = glob(os.path.join(model_dir,'*model*.pkl'))\n",
    "for i, model_path in tqdm(enumerate(model_lst)):\n",
    "    model = joblib.load(model_path)\n",
    "    y_preds += model.predict(df_all_test[feature_name])\n",
    "y_preds /= (i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_test['row_id'] = df_all_test['stock_id'].astype(str)+'-'+df_all_test['time_id'].astype(str)\n",
    "df_all_test['target'] = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = df_all_test[['row_id','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>0.001096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target\n",
       "0    0-4  0.001096"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
